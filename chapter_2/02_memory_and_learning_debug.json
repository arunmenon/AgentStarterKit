{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "course-header",
   "metadata": {},
   "source": [
    "# Module 2: Agent Memory and Learning
    "*Building Agents That Remember and Improve*
    "
    "**Learning Objectives:**
    "- Implement sophisticated memory systems for agents
    "- Create agents that learn from conversation history
    "- Build context-aware systems that improve over time
    "- Design memory retrieval and summarization mechanisms
    "
    "**Duration:** 50 minutes
    "
    "**Prerequisites:** Completion of Module 1 (Agent Foundations)
    "
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-introduction",
   "metadata": {},
   "source": [
    "## 🧠 Why Memory Matters for Agents
    "
    "In Module 1, we built agents that could reason and act, but they had limited memory. Each interaction was largely independent. **Real agentic systems need sophisticated memory** to:
    "
    "### 🔄 Maintain Context Across Interactions
    "- Remember previous conversations with users
    "- Maintain awareness of ongoing projects and tasks
    "- Build relationships through persistent interaction history
    "
    "### 📚 Learn from Experience
    "- Identify patterns in successful strategies
    "- Avoid repeating previous mistakes
    "- Adapt behavior based on user preferences
    "
    "### 🎯 Personalize Responses
    "- Tailor communication style to individual users
    "- Remember user goals and preferences
    "- Provide contextually appropriate assistance
    "
    "### 📈 Improve Performance Over Time
    "- Develop expertise in specific domains
    "- Optimize tool usage patterns
    "- Build knowledge bases from experience
    "
    "---
    "
    "## 🏗️ Types of Agent Memory
    "
    "Modern agentic systems typically implement multiple memory types working together:
    "
    "### 1. **Working Memory** (Short-term)
    "- Current conversation context
    "- Active task state and progress
    "- Immediate observations and reasoning
    "
    "### 2. **Episodic Memory** (Experience-based)
    "- Specific past interactions and events
    "- Success/failure patterns
    "- User interaction history
    "
    "### 3. **Semantic Memory** (Knowledge-based)
    "- Learned facts and concepts
    "- General strategies and approaches
    "- Domain expertise accumulated over time
    "
    "### 4. **Procedural Memory** (Skill-based)
    "- Tool usage patterns
    "- Problem-solving procedures
    "- Workflow optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced imports for memory and learning systems
    "import openai
    "import json
    "import pickle
    "import hashlib
    "import numpy as np
    "from datetime import datetime, timedelta
    "from typing import List, Dict, Any, Optional, Tuple
    "from dataclasses import dataclass, field
    "from collections import defaultdict, deque
    "import sqlite3
    "import os
    "from dotenv import load_dotenv
    "import matplotlib.pyplot as plt
    "import seaborn as sns
    "
    "# Load environment
    "load_dotenv()
    "
    "# Helper functions from Module 1
    "def print_section(title: str, content: str):
    "    \"\"\"Helper function to format output sections clearly\"\"\"
    "    print(f\"\\n{'='*50}\")
    "    print(f\"🧠 {title}\")
    "    print(f\"{'='*50}\")
    "    print(content)
    "    print(f\"{'='*50}\\n\")
    "
    "print(\"✅ Memory system imports ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-structures",
   "metadata": {},
   "source": [
    "## 🗄️ Building Advanced Memory Structures
    "
    "Let's implement sophisticated memory systems that can store, retrieve, and learn from different types of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-dataclasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced memory data structures
    "
    "@dataclass
    "class MemoryItem:
    "    \"\"\"Base class for all memory items\"\"\"
    "    id: str
    "    content: str
    "    timestamp: datetime
    "    importance: float  # 0.0 to 1.0 importance score
    "    access_count: int = 0
    "    last_accessed: Optional[datetime] = None
    "    tags: List[str] = field(default_factory=list)
    "    
    "    def access(self):
    "        \"\"\"Update access statistics when memory is retrieved\"\"\"
    "        self.access_count += 1
    "        self.last_accessed = datetime.now()
    "
    "@dataclass 
    "class ConversationMemory(MemoryItem):
    "    \"\"\"Stores conversation history with context\"\"\"
    "    user_id: str
    "    conversation_id: str
    "    message_type: str  # \"user\", \"assistant\", \"system\"
    "    context: Dict[str, Any] = field(default_factory=dict)
    "
    "@dataclass
    "class ExperienceMemory(MemoryItem):
    "    \"\"\"Stores agent experiences and outcomes\"\"\"
    "    action_taken: str
    "    context: str
    "    outcome: str
    "    success: bool
    "    learned_pattern: Optional[str] = None
    "
    "@dataclass
    "class KnowledgeMemory(MemoryItem):
    "    \"\"\"Stores learned facts and concepts\"\"\"
    "    concept: str
    "    domain: str
    "    confidence: float  # How confident the agent is in this knowledge
    "    sources: List[str] = field(default_factory=list)
    "
    "@dataclass
    "class UserPreference(MemoryItem):
    "    \"\"\"Stores user preferences and personalization data\"\"\"
    "    user_id: str
    "    preference_type: str  # \"communication_style\", \"task_preference\", etc.
    "    value: Any
    "    confidence: float = 0.5
    "
    "print(\"✅ Memory data structures defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-manager",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedMemoryManager:
    "    \"\"\"Sophisticated memory management system for agents\"\"\"
    "    
    "    def __init__(self, max_working_memory: int = 10, max_total_memory: int = 1000):
    "        self.max_working_memory = max_working_memory
    "        self.max_total_memory = max_total_memory
    "        
    "        # Different memory stores
    "        self.working_memory = deque(maxlen=max_working_memory)  # Recent context
    "        self.episodic_memory: List[MemoryItem] = []  # Experiences and conversations
    "        self.semantic_memory: Dict[str, KnowledgeMemory] = {}  # Facts and concepts
    "        self.procedural_memory: Dict[str, ExperienceMemory] = {}  # Skills and patterns
    "        self.user_preferences: Dict[str, Dict[str, UserPreference]] = defaultdict(dict)
    "        
    "        # Memory statistics
    "        self.total_memories = 0
    "        self.successful_retrievals = 0
    "        self.failed_retrievals = 0
    "    
    "    def add_conversation(self, user_id: str, message: str, message_type: str, 
    "                        conversation_id: str = \"default\", importance: float = 0.5) -> str:
    "        \"\"\"Add a conversation message to memory\"\"\"
    "        memory_id = self._generate_id(f\"conv_{user_id}_{conversation_id}_{len(self.episodic_memory)}\")
    "        
    "        conv_memory = ConversationMemory(
    "            id=memory_id,
    "            content=message,
    "            timestamp=datetime.now(),
    "            importance=importance,
    "            user_id=user_id,
    "            conversation_id=conversation_id,
    "            message_type=message_type
    "        )
    "        
    "        # Add to working memory (most recent)
    "        self.working_memory.append(conv_memory)
    "        
    "        # Add to episodic memory
    "        self.episodic_memory.append(conv_memory)
    "        self.total_memories += 1
    "        
    "        # Auto-tag based on content
    "        conv_memory.tags = self._extract_tags(message)
    "        
    "        return memory_id
    "    
    "    def add_experience(self, action: str, context: str, outcome: str, 
    "                      success: bool, importance: float = 0.7) -> str:
    "        \"\"\"Add an experience/learning event to memory\"\"\"
    "        memory_id = self._generate_id(f\"exp_{action}_{len(self.episodic_memory)}\")
    "        
    "        exp_memory = ExperienceMemory(
    "            id=memory_id,
    "            content=f\"Action: {action} | Context: {context} | Outcome: {outcome}\",
    "            timestamp=datetime.now(),
    "            importance=importance,
    "            action_taken=action,
    "            context=context,
    "            outcome=outcome,
    "            success=success
    "        )
    "        
    "        # Analyze for patterns
    "        pattern = self._analyze_experience_pattern(exp_memory)
    "        if pattern:
    "            exp_memory.learned_pattern = pattern
    "            # Store in procedural memory for quick access
    "            self.procedural_memory[action] = exp_memory
    "        
    "        self.episodic_memory.append(exp_memory)
    "        self.total_memories += 1
    "        
    "        return memory_id
    "    
    "    def add_knowledge(self, concept: str, content: str, domain: str, 
    "                     confidence: float = 0.8, sources: List[str] = None) -> str:
    "        \"\"\"Add factual knowledge to semantic memory\"\"\"
    "        memory_id = self._generate_id(f\"know_{concept}_{domain}\")
    "        
    "        knowledge = KnowledgeMemory(
    "            id=memory_id,
    "            content=content,
    "            timestamp=datetime.now(),
    "            importance=0.8,  # Knowledge is generally important
    "            concept=concept,
    "            domain=domain,
    "            confidence=confidence,
    "            sources=sources or []
    "        )
    "        
    "        self.semantic_memory[concept] = knowledge
    "        self.total_memories += 1
    "        
    "        return memory_id
    "    
    "    def retrieve_relevant_memories(self, query: str, memory_types: List[str] = None, 
    "                                 limit: int = 5) -> List[MemoryItem]:
    "        \"\"\"Retrieve memories relevant to a query using multiple strategies\"\"\"
    "        
    "        if memory_types is None:
    "            memory_types = [\"conversation\", \"experience\", \"knowledge\"]
    "        
    "        relevant_memories = []
    "        
    "        # Search in different memory stores
    "        if \"conversation\" in memory_types:
    "            relevant_memories.extend(self._search_conversations(query))
    "        
    "        if \"experience\" in memory_types:
    "            relevant_memories.extend(self._search_experiences(query))
    "        
    "        if \"knowledge\" in memory_types:
    "            relevant_memories.extend(self._search_knowledge(query))
    "        
    "        # Score and rank memories
    "        scored_memories = []
    "        for memory in relevant_memories:
    "            relevance_score = self._calculate_relevance_score(memory, query)
    "            scored_memories.append((relevance_score, memory))
    "        
    "        # Sort by relevance and return top results
    "        scored_memories.sort(reverse=True, key=lambda x: x[0])
    "        top_memories = [memory for _, memory in scored_memories[:limit]]
    "        
    "        # Update access statistics
    "        for memory in top_memories:
    "            memory.access()
    "        
    "        if top_memories:
    "            self.successful_retrievals += 1
    "        else:
    "            self.failed_retrievals += 1
    "        
    "        return top_memories
    "    
    "    def get_working_memory_context(self) -> str:
    "        \"\"\"Get recent conversation context for current interaction\"\"\"
    "        if not self.working_memory:
    "            return \"No recent conversation context.\"
    "        
    "        context_parts = []
    "        for memory in self.working_memory:
    "            if isinstance(memory, ConversationMemory):
    "                context_parts.append(f\"{memory.message_type}: {memory.content}\")
    "        
    "        return \"\\n\".join(context_parts[-5:])  # Last 5 messages
    "    
    "    def learn_user_preference(self, user_id: str, preference_type: str, 
    "                            value: Any, confidence: float = 0.6):
    "        \"\"\"Learn and update user preferences\"\"\"
    "        memory_id = self._generate_id(f\"pref_{user_id}_{preference_type}\")
    "        
    "        preference = UserPreference(
    "            id=memory_id,
    "            content=f\"{preference_type}: {value}\",
    "            timestamp=datetime.now(),
    "            importance=0.6,
    "            user_id=user_id,
    "            preference_type=preference_type,
    "            value=value,
    "            confidence=confidence
    "        )
    "        
    "        # Update or add preference
    "        if preference_type in self.user_preferences[user_id]:
    "            # Update existing preference with confidence weighting
    "            existing = self.user_preferences[user_id][preference_type]
    "            new_confidence = (existing.confidence + confidence) / 2
    "            preference.confidence = min(new_confidence, 0.95)  # Cap confidence
    "        
    "        self.user_preferences[user_id][preference_type] = preference
    "    
    "    def get_memory_statistics(self) -> Dict[str, Any]:
    "        \"\"\"Get comprehensive memory statistics\"\"\"
    "        return {
    "            "total_memories": self.total_memories,
    "            "working_memory_size": len(self.working_memory),
    "            "episodic_memories": len(self.episodic_memory),
    "            "semantic_concepts": len(self.semantic_memory),
    "            "procedural_patterns": len(self.procedural_memory),
    "            "users_tracked": len(self.user_preferences),
    "            "retrieval_success_rate": (
    "                self.successful_retrievals / 
    "                max(1, self.successful_retrievals + self.failed_retrievals)
    "            ) * 100
    "        },
    "    
    "    # Helper methods
    "    def _generate_id(self, content: str) -> str:
    "        \"\"\"Generate unique ID for memory items\"\"\"
    "        return hashlib.md5(f\"{content}_{datetime.now().isoformat()}\".encode()).hexdigest()[:12]
    "    
    "    def _extract_tags(self, content: str) -> List[str]:
    "        \"\"\"Extract relevant tags from content\"\"\"
    "        # Simple keyword extraction (in production, use NLP)
    "        keywords = [\"question\", \"request\", \"problem\", \"help\", \"information\", \"task\", \"goal\"]
    "        tags = []
    "        content_lower = content.lower()
    "        
    "        for keyword in keywords:
    "            if keyword in content_lower:
    "                tags.append(keyword)
    "        
    "        return tags
    "    
    "    def _analyze_experience_pattern(self, experience: ExperienceMemory) -> Optional[str]:
    "        \"\"\"Analyze experience for learnable patterns\"\"\"
    "        if experience.success:
    "            return f\"Successful strategy: {experience.action_taken} works well for {experience.context}\"
    "        else:
    "            return f\"Avoid: {experience.action_taken} not effective for {experience.context}\"
    "    
    "    def _search_conversations(self, query: str) -> List[ConversationMemory]:
    "        \"\"\"Search conversation memories\"\"\"
    "        matches = []
    "        query_lower = query.lower()
    "        
    "        for memory in self.episodic_memory:
    "            if isinstance(memory, ConversationMemory):
    "                if query_lower in memory.content.lower():
    "                    matches.append(memory)
    "        
    "        return matches
    "    
    "    def _search_experiences(self, query: str) -> List[ExperienceMemory]:
    "        \"\"\"Search experience memories\"\"\"
    "        matches = []
    "        query_lower = query.lower()
    "        
    "        for memory in self.episodic_memory:
    "            if isinstance(memory, ExperienceMemory):
    "                if (query_lower in memory.action_taken.lower() or 
    "                    query_lower in memory.context.lower()):
    "                    matches.append(memory)
    "        
    "        return matches
    "    
    "    def _search_knowledge(self, query: str) -> List[KnowledgeMemory]:
    "        \"\"\"Search semantic knowledge\"\"\"
    "        matches = []
    "        query_lower = query.lower()
    "        
    "        for concept, memory in self.semantic_memory.items():
    "            if (query_lower in concept.lower() or 
    "                query_lower in memory.content.lower() or
    "                query_lower in memory.domain.lower()):
    "                matches.append(memory)
    "        
    "        return matches
    "    
    "    def _calculate_relevance_score(self, memory: MemoryItem, query: str) -> float:
    "        \"\"\"Calculate how relevant a memory is to a query\"\"\"
    "        base_score = 0.0
    "        query_lower = query.lower()
    "        content_lower = memory.content.lower()
    "        
    "        # Content matching
    "        if query_lower in content_lower:
    "            base_score += 0.5
    "        
    "        # Importance weighting
    "        base_score += memory.importance * 0.3
    "        
    "        # Recency bonus (newer memories are slightly more relevant)
    "        days_old = (datetime.now() - memory.timestamp).days
    "        recency_bonus = max(0, 0.2 - (days_old * 0.01))
    "        base_score += recency_bonus
    "        
    "        # Access frequency bonus
    "        access_bonus = min(0.1, memory.access_count * 0.02)
    "        base_score += access_bonus
    "        
    "        return min(1.0, base_score)  # Cap at 1.0
    "
    "# Create an advanced memory manager
    "memory_manager = AdvancedMemoryManager()
    "print(\"✅ Advanced Memory Manager created!\")
    "print(f\"📊 Initial stats: {memory_manager.get_memory_statistics()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learning-agent",
   "metadata": {},
   "source": [
    "## 🎓 Building a Learning Agent
    "
    "Now let's create an agent that uses our advanced memory system to learn and improve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning-agent-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningAgent:
    "    \"\"\"An agent that learns and improves through experience and memory\"\"\"
    "    
    "    def __init__(self, name: str, api_key: str, memory_manager: AdvancedMemoryManager):
    "        self.name = name
    "        self.client = openai.OpenAI(api_key=api_key)
    "        self.memory = memory_manager
    "        self.tools = {}
    "        self.current_user = None
    "        self.conversation_count = 0
    "        
    "        # Learning metrics
    "        self.successful_tasks = 0
    "        self.failed_tasks = 0
    "        self.learning_events = 0
    "    
    "    def add_tool(self, tool_name: str, tool_function, description: str):
    "        \"\"\"Add a tool to the agent's arsenal\"\"\"
    "        self.tools[tool_name] = {
    "            'function': tool_function,
    "            'description': description
    "        },
    "        
    "        # Learn about this new capability
    "        self.memory.add_knowledge(
    "            concept=f\"tool_{tool_name}\",
    "            content=description,
    "            domain=\"tools_and_capabilities\",
    "            confidence=1.0
    "        )
    "    
    "    def chat(self, user_message: str, user_id: str = \"user\") -> str:
    "        \"\"\"Have a conversation with learning and memory\"\"\"
    "        self.current_user = user_id
    "        self.conversation_count += 1
    "        
    "        # Store user message in memory
    "        self.memory.add_conversation(
    "            user_id=user_id,
    "            message=user_message,
    "            message_type=\"user\",
    "            conversation_id=f\"conv_{self.conversation_count}\",
    "            importance=0.6
    "        )
    "        
    "        # Retrieve relevant context from memory
    "        relevant_memories = self.memory.retrieve_relevant_memories(
    "            query=user_message,
    "            limit=3
    "        )
    "        
    "        # Get user preferences
    "        user_prefs = self.memory.user_preferences.get(user_id, {})
    "        
    "        # Build context-aware prompt
    "        context_prompt = self._build_context_prompt(
    "            user_message, relevant_memories, user_prefs
    "        )
    "        
    "        try:
    "            # Generate response
    "            response = self.client.chat.completions.create(
    "                model=\"gpt-4\",
    "                messages=[
    "                    {"role": \"system\", "content": context_prompt},
    "                    {"role": \"user\", "content": user_message}
    "                ],
    "                temperature=0.7,
    "                max_tokens=500
    "            )
    "            
    "            assistant_response = response.choices[0].message.content
    "            
    "            # Store assistant response
    "            self.memory.add_conversation(
    "                user_id=user_id,
    "                message=assistant_response,
    "                message_type=\"assistant\",
    "                conversation_id=f\"conv_{self.conversation_count}\",
    "                importance=0.5
    "            )
    "            
    "            # Learn from interaction
    "            self._learn_from_interaction(user_message, assistant_response, user_id)
    "            
    "            return assistant_response
    "            
    "        except Exception as e:
    "            error_msg = f\"I encountered an error: {str(e)}\"
    "            
    "            # Learn from failure
    "            self.memory.add_experience(
    "                action=\"generate_response\",
    "                context=f\"User query: {user_message[:100]}\",
    "                outcome=error_msg,
    "                success=False,
    "                importance=0.8
    "            )
    "            
    "            return error_msg
    "    
    "    def execute_task_with_learning(self, task: str, user_id: str = \"user\") -> str:
    "        \"\"\"Execute a complex task with learning and memory\"\"\"
    "        print_section(\"STARTING LEARNING TASK\", f\"Task: {task}\")
    "        
    "        # Check if we've done similar tasks before
    "        similar_experiences = self.memory.retrieve_relevant_memories(
    "            query=task,
    "            memory_types=[\"experience\"],
    "            limit=3
    "        )
    "        
    "        learned_strategies = []
    "        for exp in similar_experiences:
    "            if isinstance(exp, ExperienceMemory) and exp.learned_pattern:
    "                learned_strategies.append(exp.learned_pattern)
    "        
    "        if learned_strategies:
    "            print(f\"📚 Using learned strategies: {len(learned_strategies)} patterns found\")
    "            for strategy in learned_strategies:
    "                print(f\"  💡 {strategy}\")
    "        
    "        # Execute task with ReAct pattern + learning
    "        result = self._execute_react_with_learning(task, user_id)
    "        
    "        return result
    "    
    "    def _build_context_prompt(self, user_message: str, relevant_memories: List[MemoryItem], 
    "                            user_prefs: Dict[str, UserPreference]) -> str:
    "        \"\"\"Build a context-aware prompt using memory and preferences\"\"\"
    "        
    "        prompt = f\"You are {self.name}, a learning AI assistant with memory and experience.\\n\\n\"
    "        
    "        # Add recent conversation context
    "        recent_context = self.memory.get_working_memory_context()
    "        if recent_context and \"No recent\" not in recent_context:
    "            prompt += f\"Recent conversation context:\\n{recent_context}\\n\\n\"
    "        
    "        # Add relevant memories
    "        if relevant_memories:
    "            prompt += \"Relevant memories:\\n\"
    "            for memory in relevant_memories:
    "                memory_type = type(memory).__name__
    "                prompt += f\"- [{memory_type}] {memory.content[:100]}...\\n\"
    "            prompt += \"\\n\"
    "        
    "        # Add user preferences
    "        if user_prefs:
    "            prompt += \"User preferences:\\n\"
    "            for pref_type, preference in user_prefs.items():
    "                prompt += f\"- {pref_type}: {preference.value} (confidence: {preference.confidence:.2f})\\n\"
    "            prompt += \"\\n\"
    "        
    "        # Add available tools
    "        if self.tools:
    "            prompt += \"Available tools:\\n\"
    "            for tool_name, tool_info in self.tools.items():
    "                prompt += f\"- {tool_name}: {tool_info['description']}\\n\"
    "            prompt += \"\\n\"
    "        
    "        prompt += \"\"\"Instructions:
    "- Use your memory and experience to provide helpful, personalized responses
    "- Learn from each interaction to improve future responses
    "- Be contextually aware and reference relevant past conversations when appropriate
    "- Adapt your communication style based on user preferences
    "- If you use tools, explain your reasoning
    "\"\"\"
    "        
    "        return prompt
    "    
    "    def _learn_from_interaction(self, user_message: str, assistant_response: str, user_id: str):
    "        \"\"\"Extract learning from the interaction\"\"\"
    "        
    "        # Analyze communication patterns
    "        if \"?\" in user_message:
    "            self.memory.learn_user_preference(
    "                user_id=user_id,
    "                preference_type=\"asks_questions\",
    "                value=True,
    "                confidence=0.6
    "            )
    "        
    "        # Analyze response length preference
    "        response_length = len(assistant_response.split())
    "        if response_length > 100:
    "            self.memory.learn_user_preference(
    "                user_id=user_id,
    "                preference_type=\"prefers_detailed_responses\",
    "                value=True,
    "                confidence=0.5
    "            )
    "        
    "        # Record successful interaction
    "        self.memory.add_experience(
    "            action=\"respond_to_user\",
    "            context=f\"Query type: {self._categorize_query(user_message)}\",
    "            outcome=\"Response generated successfully\",
    "            success=True,
    "            importance=0.4
    "        )
    "        
    "        self.learning_events += 1
    "    
    "    def _categorize_query(self, message: str) -> str:
    "        \"\"\"Categorize the type of user query\"\"\"
    "        message_lower = message.lower()
    "        
    "        if any(word in message_lower for word in [\"what\", \"how\", \"why\", \"when\", \"where\"]):
    "            return \"question\"
    "        elif any(word in message_lower for word in [\"please\", \"can you\", \"help\", \"need\"]):
    "            return \"request\"
    "        elif any(word in message_lower for word in [\"thanks\", \"thank you\", \"good\", \"great\"]):
    "            return \"appreciation\"
    "        else:
    "            return \"general\"
    "    
    "    def _execute_react_with_learning(self, task: str, user_id: str) -> str:
    "        \"\"\"Execute ReAct pattern enhanced with learning\"\"\"
    "        # This is a simplified version - in a complete implementation,
    "        # this would integrate the full ReAct loop from Module 1
    "        # with memory-enhanced decision making
    "        
    "        try:
    "            result = f\"Task completed: {task}\"
    "            
    "            # Record successful task completion
    "            self.memory.add_experience(
    "                action=\"complete_task\",
    "                context=f\"Task: {task[:100]}\",
    "                outcome=\"Successfully completed\",
    "                success=True,
    "                importance=0.7
    "            )
    "            
    "            self.successful_tasks += 1
    "            return result
    "            
    "        except Exception as e:
    "            # Learn from failure
    "            self.memory.add_experience(
    "                action=\"complete_task\",
    "                context=f\"Task: {task[:100]}\",
    "                outcome=f\"Failed: {str(e)}\",
    "                success=False,
    "                importance=0.8
    "            )
    "            
    "            self.failed_tasks += 1
    "            return f\"Task failed: {str(e)}\"
    "    
    "    def get_learning_statistics(self) -> Dict[str, Any]:
    "        \"\"\"Get comprehensive learning statistics\"\"\"
    "        memory_stats = self.memory.get_memory_statistics()
    "        
    "        return {
    "            **memory_stats,
    "            "conversations_held": self.conversation_count,
    "            "successful_tasks": self.successful_tasks,
    "            "failed_tasks": self.failed_tasks,
    "            "task_success_rate": (
    "                self.successful_tasks / max(1, self.successful_tasks + self.failed_tasks)
    "            ) * 100,
    "            "learning_events": self.learning_events,
    "            "tools_available": len(self.tools)
    "        },
    "
    "# Create a learning agent
    "learning_agent = LearningAgent(
    "    name=\"MemoryBot\",
    "    api_key=os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\"),
    "    memory_manager=memory_manager
    ")
    "
    "print(\"✅ Learning Agent created!\")
    "print(f\"📊 Initial learning stats: {learning_agent.get_learning_statistics()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-exercise-memory",
   "metadata": {},
   "source": [
    "## 💡 Guided Exercise: Implement Memory-Enhanced Tools
    "
    "Your task is to create tools that can learn and improve from usage patterns.
    "
    "**Exercise:** Implement a \"smart_search\" tool that remembers what searches were successful and suggests improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-exercise-memory-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartSearchTool:
    "    \"\"\"A search tool that learns from usage patterns\"\"\"
    "    
    "    def __init__(self, memory_manager: AdvancedMemoryManager):
    "        self.memory = memory_manager
    "        self.search_history = []
    "        self.successful_patterns = {}
    "    
    "    def search(self, query: str, user_feedback: str = None) -> str:
    "        \"\"\"
    "        Perform a smart search that learns from previous searches.
    "        
    "        YOUR TASK: Complete this implementation to:
    "        1. Check if we've seen similar queries before
    "        2. Use successful patterns to improve the search
    "        3. Learn from the results
    "        \"\"\"
    "        
    "        ### START CODE HERE ###
    "        
    "        # Step 1: Look for similar past searches
    "        similar_searches = # YOUR CODE: Retrieve similar search experiences from memory
    "        
    "        # Step 2: Apply learned improvements
    "        improved_query = query
    "        if similar_searches:
    "            # YOUR CODE: Check if any similar searches were successful
    "            # and extract improvement patterns
    "            for search_memory in similar_searches:
    "                if isinstance(search_memory, ExperienceMemory) and search_memory.success:
    "                    # YOUR CODE: Extract and apply successful patterns
    "                    pattern = # Extract pattern from successful search
    "                    improved_query = # Apply pattern to improve current query
    "                    break
    "        
    "        # Step 3: Perform the search (simulated)
    "        search_result = self._simulate_search(improved_query)
    "        
    "        # Step 4: Learn from this search
    "        success = # YOUR CODE: Determine if search was successful
    "        
    "        # YOUR CODE: Add this search experience to memory
    "        self.memory.add_experience(
    "            action=, # What action was taken?
    "            context=, # What was the context?
    "            outcome=, # What was the result?
    "            success=, # Was it successful?
    "            importance=0.6
    "        )
    "        
    "        # Step 5: Update search patterns if successful
    "        if success and improved_query != query:
    "            # YOUR CODE: Record the improvement pattern
    "            pattern_key = # Create a key for this pattern
    "            self.successful_patterns[pattern_key] = # Store the pattern
    "        
    "        return search_result
    "        
    "        ### END CODE HERE ###
    "    
    "    def _simulate_search(self, query: str) -> str:
    "        \"\"\"Simulate search results (in production, this would be a real search API)\"\"\"
    "        # Simple simulation based on query quality
    "        query_words = query.lower().split()
    "        
    "        if len(query_words) >= 3 and any(word in query for word in [\"latest\", \"recent\", \"2024\", \"current\"]):
    "            return f\"High-quality search results for: {query}\"
    "        elif len(query_words) >= 2:
    "            return f\"Good search results for: {query}\"
    "        else:
    "            return f\"Limited results for: {query}\"
    "    
    "    def get_search_insights(self) -> Dict[str, Any]:
    "        \"\"\"Get insights about search patterns\"\"\"
    "        return {
    "            "total_searches": len(self.search_history),
    "            "successful_patterns": len(self.successful_patterns),
    "            "pattern_examples": list(self.successful_patterns.keys())[:3]
    "        },
    "
    "# Test your implementation
    "smart_search = SmartSearchTool(memory_manager)
    "
    "# Add some initial search knowledge
    "memory_manager.add_experience(
    "    action=\"search\",
    "    context=\"Query: 'AI' improved to 'AI latest developments 2024'\",
    "    outcome=\"High-quality results found\",
    "    success=True,
    "    importance=0.7
    ")
    "
    "print(\"🔍 Testing Smart Search Tool:\")
    "result1 = smart_search.search(\"AI\")
    "print(f\"Search 1: {result1}\")
    "
    "result2 = smart_search.search(\"machine learning\")
    "print(f\"Search 2: {result2}\")
    "
    "print(f\"\\n📊 Search insights: {smart_search.get_search_insights()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution-reveal-memory",
   "metadata": {},
   "source": [
    "### 🔍 Solution Reveal
    "
    "Here's the solution for the smart search tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION - Compare with your implementation!
    "
    "\"\"\"
    "def search(self, query: str, user_feedback: str = None) -> str:
    "    # Step 1: Look for similar past searches
    "    similar_searches = self.memory.retrieve_relevant_memories(
    "        query=f\"search {query}\",
    "        memory_types=[\"experience\"],
    "        limit=3
    "    )
    "    
    "    # Step 2: Apply learned improvements
    "    improved_query = query
    "    if similar_searches:
    "        for search_memory in similar_searches:
    "            if isinstance(search_memory, ExperienceMemory) and search_memory.success:
    "                if \"improved to\" in search_memory.context:
    "                    # Extract improvement pattern
    "                    improved_query = f\"{query} latest developments 2024\"
    "                    break
    "    
    "    # Step 3: Perform the search
    "    search_result = self._simulate_search(improved_query)
    "    
    "    # Step 4: Determine success
    "    success = \"High-quality\" in search_result or \"Good\" in search_result
    "    
    "    # Step 5: Learn from this search
    "    self.memory.add_experience(
    "        action=\"search\",
    "        context=f\"Query: '{query}' processed as '{improved_query}'\",
    "        outcome=search_result,
    "        success=success,
    "        importance=0.6
    "    )
    "    
    "    # Step 6: Update patterns
    "    if success and improved_query != query:
    "        pattern_key = f\"add_recent_context_{query.split()[0]}\"
    "        self.successful_patterns[pattern_key] = \"Add temporal context to improve search\"
    "    
    "    return search_result
    "\"\"\"
    "
    "print(\"💡 Solution revealed! Compare with your implementation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conversation-learning",
   "metadata": {},
   "source": [
    "## 🗣️ Hands-On Exercise: Conversational Learning
    "
    "Let's test our learning agent with a series of conversations to see how it learns and adapts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conversation-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the smart search tool to our learning agent
    "smart_search = SmartSearchTool(memory_manager)
    "
    "def smart_search_wrapper(query: str) -> str:
    "    return smart_search.search(query)
    "
    "learning_agent.add_tool(
    "    tool_name=\"smart_search\",
    "    tool_function=smart_search_wrapper,
    "    description=\"Intelligent search that learns from usage patterns\"
    ")
    "
    "# Simulate a series of conversations to demonstrate learning
    "print_section(\"CONVERSATIONAL LEARNING DEMONSTRATION\", \"Watch how the agent learns from interactions\")
    "
    "# Conversation 1: Initial interaction
    "print(\"\\n--- Conversation 1: First Meeting ---\")
    "response1 = learning_agent.chat(
    "    \"Hi! I'm Alice. I prefer detailed explanations and I'm interested in AI research.\",
    "    user_id=\"alice\"
    ")
    "print(f\"Agent: {response1}\")
    "
    "# Conversation 2: Follow-up question
    "print(\"\\n--- Conversation 2: Follow-up ---\")
    "response2 = learning_agent.chat(
    "    \"Can you tell me about the latest developments in machine learning?\",
    "    user_id=\"alice\"
    ")
    "print(f\"Agent: {response2}\")
    "
    "# Conversation 3: Different user with different style
    "print(\"\\n--- Conversation 3: New User ---\")
    "response3 = learning_agent.chat(
    "    \"Quick question - what's AI?\",
    "    user_id=\"bob\"
    ")
    "print(f\"Agent: {response3}\")
    "
    "# Conversation 4: Alice returns - should show personalization
    "print(\"\\n--- Conversation 4: Alice Returns ---\")
    "response4 = learning_agent.chat(
    "    \"What did we discuss before about AI?\",
    "    user_id=\"alice\"
    ")
    "print(f\"Agent: {response4}\")
    "
    "# Show learning statistics
    "print(\"\\n\" + \"=\"*60)
    "print(\"📊 LEARNING STATISTICS\")
    "print(\"=\"*60)
    "stats = learning_agent.get_learning_statistics()
    "for key, value in stats.items():
    "    print(f\"{key}: {value}\")
    "
    "# Show specific user preferences learned
    "print(\"\\n📚 Learned User Preferences:\")
    "for user_id, prefs in memory_manager.user_preferences.items():
    "    print(f\"\\nUser: {user_id}\")
    "    for pref_type, pref in prefs.items():
    "        print(f\"  - {pref_type}: {pref.value} (confidence: {pref.confidence:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-visualization",
   "metadata": {},
   "source": [
    "## 📊 Memory Visualization and Analysis
    "
    "Let's create visualizations to understand how the agent's memory and learning are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-visualization-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_memory_statistics(memory_manager: AdvancedMemoryManager):
    "    \"\"\"Create visualizations of memory usage and learning patterns\"\"\"
    "    
    "    # Prepare data
    "    stats = memory_manager.get_memory_statistics()
    "    
    "    # Create subplots
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    "    fig.suptitle('Agent Memory and Learning Analysis', fontsize=16, fontweight='bold')
    "    
    "    # 1. Memory Distribution
    "    memory_types = ['Episodic', 'Semantic', 'Procedural', 'Working']
    "    memory_counts = [
    "        stats['episodic_memories'],
    "        stats['semantic_concepts'],
    "        stats['procedural_patterns'],
    "        stats['working_memory_size']
    "    ]
    "    
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
    "    ax1.pie(memory_counts, labels=memory_types, colors=colors, autopct='%1.1f%%', startangle=90)
    "    ax1.set_title('Memory Distribution by Type')
    "    
    "    # 2. Memory Access Patterns
    "    access_data = []
    "    for memory in memory_manager.episodic_memory[-20:]:  # Last 20 memories
    "        access_data.append(memory.access_count)
    "    
    "    ax2.bar(range(len(access_data)), access_data, color='#FF6B6B', alpha=0.7)
    "    ax2.set_title('Memory Access Frequency (Recent 20)')
    "    ax2.set_xlabel('Memory Item')
    "    ax2.set_ylabel('Access Count')
    "    
    "    # 3. Importance Distribution
    "    importance_levels = [0, 0, 0, 0, 0]  # 0-0.2, 0.2-0.4, 0.4-0.6, 0.6-0.8, 0.8-1.0
    "    for memory in memory_manager.episodic_memory:
    "        bucket = min(4, int(memory.importance * 5))
    "        importance_levels[bucket] += 1
    "    
    "    importance_labels = ['0-0.2', '0.2-0.4', '0.4-0.6', '0.6-0.8', '0.8-1.0']
    "    ax3.bar(importance_labels, importance_levels, color='#4ECDC4', alpha=0.7)
    "    ax3.set_title('Memory Importance Distribution')
    "    ax3.set_xlabel('Importance Level')
    "    ax3.set_ylabel('Number of Memories')
    "    ax3.tick_params(axis='x', rotation=45)
    "    
    "    # 4. User Interaction Timeline
    "    user_interactions = defaultdict(int)
    "    for memory in memory_manager.episodic_memory:
    "        if isinstance(memory, ConversationMemory):
    "            user_interactions[memory.user_id] += 1
    "    
    "    users = list(user_interactions.keys())
    "    interactions = list(user_interactions.values())
    "    
    "    if users:  # Only plot if we have user data
    "        ax4.bar(users, interactions, color='#45B7D1', alpha=0.7)
    "        ax4.set_title('Interactions by User')
    "        ax4.set_xlabel('User ID')
    "        ax4.set_ylabel('Number of Interactions')
    "    else:
    "        ax4.text(0.5, 0.5, 'No user interaction data', ha='center', va='center', transform=ax4.transAxes)
    "        ax4.set_title('Interactions by User')
    "    
    "    plt.tight_layout()
    "    plt.show()
    "    
    "    # Print detailed statistics
    "    print(\"\\n📈 Detailed Memory Statistics:\")
    "    print(f\"Total memories stored: {stats['total_memories']}\")
    "    print(f\"Retrieval success rate: {stats['retrieval_success_rate']:.1f}%\")
    "    print(f\"Users tracked: {stats['users_tracked']}\")
    "    
    "    # Memory efficiency analysis
    "    if memory_manager.episodic_memory:
    "        avg_importance = sum(m.importance for m in memory_manager.episodic_memory) / len(memory_manager.episodic_memory)
    "        avg_access = sum(m.access_count for m in memory_manager.episodic_memory) / len(memory_manager.episodic_memory)
    "        
    "        print(f\"\\n🧠 Memory Quality Metrics:\")
    "        print(f\"Average memory importance: {avg_importance:.3f}\")
    "        print(f\"Average access count: {avg_access:.1f}\")
    "        
    "        # Find most accessed memories
    "        top_memories = sorted(memory_manager.episodic_memory, key=lambda x: x.access_count, reverse=True)[:3]
    "        print(f\"\\n🏆 Most Accessed Memories:\")
    "        for i, memory in enumerate(top_memories, 1):
    "            print(f\"{i}. {memory.content[:60]}... (accessed {memory.access_count} times)\")
    "
    "# Generate visualization
    "print(\"📊 Generating memory analysis visualizations...\")
    "visualize_memory_statistics(memory_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-memory-exercise",
   "metadata": {},
   "source": [
    "## 🎯 Advanced Exercise: Memory Consolidation
    "
    "Implement a memory consolidation system that can:
    "1. Identify and merge similar memories
    "2. Promote important memories to long-term storage
    "3. Archive or delete low-importance, rarely accessed memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryConsolidationSystem:
    "    \"\"\"System for managing memory consolidation and optimization\"\"\"
    "    
    "    def __init__(self, memory_manager: AdvancedMemoryManager):
    "        self.memory = memory_manager
    "        self.consolidation_threshold = 0.7  # Similarity threshold for merging
    "        self.promotion_threshold = 0.8     # Importance threshold for promotion
    "        self.archival_threshold = 0.2      # Below this, consider for archival
    "    
    "    def consolidate_memories(self) -> Dict[str, int]:
    "        \"\"\"
    "        YOUR TASK: Implement memory consolidation logic
    "        
    "        Steps to implement:
    "        1. Find similar memories that can be merged
    "        2. Promote high-importance memories
    "        3. Archive low-value memories
    "        4. Return statistics about the consolidation
    "        \"\"\"
    "        
    "        consolidation_stats = {
    "            "memories_merged": 0,
    "            "memories_promoted": 0,
    "            "memories_archived": 0,
    "            "total_processed": 0
    "        },
    "        
    "        ### START CODE HERE ###
    "        
    "        # Step 1: Find and merge similar memories
    "        # YOUR CODE: Implement similarity detection and merging
    "        for i, memory1 in enumerate(self.memory.episodic_memory):
    "            for j, memory2 in enumerate(self.memory.episodic_memory[i+1:], i+1):
    "                similarity = # YOUR CODE: Calculate similarity between memories
    "                
    "                if similarity > self.consolidation_threshold:
    "                    # YOUR CODE: Merge similar memories
    "                    merged_memory = # Create merged memory
    "                    # Update memory store
    "                    consolidation_stats[\"memories_merged\"] += 1
    "        
    "        # Step 2: Promote important memories
    "        # YOUR CODE: Identify and promote high-importance memories
    "        for memory in self.memory.episodic_memory:
    "            if memory.importance > self.promotion_threshold:
    "                # YOUR CODE: Promote to long-term storage
    "                self._promote_memory(memory)
    "                consolidation_stats[\"memories_promoted\"] += 1
    "        
    "        # Step 3: Archive low-value memories
    "        # YOUR CODE: Identify and archive low-value memories
    "        memories_to_archive = []
    "        for memory in self.memory.episodic_memory:
    "            if self._should_archive(memory):
    "                memories_to_archive.append(memory)
    "        
    "        for memory in memories_to_archive:
    "            # YOUR CODE: Archive the memory
    "            self._archive_memory(memory)
    "            consolidation_stats[\"memories_archived\"] += 1
    "        
    "        consolidation_stats[\"total_processed\"] = len(self.memory.episodic_memory)
    "        
    "        ### END CODE HERE ###
    "        
    "        return consolidation_stats
    "    
    "    def _calculate_memory_similarity(self, memory1: MemoryItem, memory2: MemoryItem) -> float:
    "        \"\"\"Calculate similarity between two memories\"\"\"
    "        # Simple similarity based on content overlap
    "        content1_words = set(memory1.content.lower().split())
    "        content2_words = set(memory2.content.lower().split())
    "        
    "        if not content1_words or not content2_words:
    "            return 0.0
    "        
    "        intersection = len(content1_words.intersection(content2_words))
    "        union = len(content1_words.union(content2_words))
    "        
    "        return intersection / union if union > 0 else 0.0
    "    
    "    def _should_archive(self, memory: MemoryItem) -> bool:
    "        \"\"\"Determine if a memory should be archived\"\"\"
    "        # Archive if low importance, old, and rarely accessed
    "        age_days = (datetime.now() - memory.timestamp).days
    "        
    "        return (
    "            memory.importance < self.archival_threshold and
    "            age_days > 7 and
    "            memory.access_count < 2
    "        )
    "    
    "    def _promote_memory(self, memory: MemoryItem):
    "        \"\"\"Promote memory to long-term storage\"\"\"
    "        memory.importance = min(1.0, memory.importance + 0.1)
    "        memory.tags.append(\"promoted\")
    "    
    "    def _archive_memory(self, memory: MemoryItem):
    "        \"\"\"Archive a memory (remove from active memory)\"\"\"
    "        if memory in self.memory.episodic_memory:
    "            self.memory.episodic_memory.remove(memory)
    "
    "# Test the consolidation system
    "consolidation_system = MemoryConsolidationSystem(memory_manager)
    "
    "print(\"🔧 Testing Memory Consolidation System...\")
    "print(f\"Memories before consolidation: {len(memory_manager.episodic_memory)}\")
    "
    "# Add some test memories with different characteristics
    "memory_manager.add_conversation(\"alice\", \"I love machine learning\", \"user\", importance=0.9)
    "memory_manager.add_conversation(\"alice\", \"Machine learning is fascinating\", \"user\", importance=0.85)
    "memory_manager.add_conversation(\"bob\", \"Weather is nice\", \"user\", importance=0.1)
    "
    "# Run consolidation
    "stats = consolidation_system.consolidate_memories()
    "
    "print(f\"\\n📊 Consolidation Results:\")
    "for key, value in stats.items():
    "    print(f\"{key}: {value}\")
    "
    "print(f\"\\nMemories after consolidation: {len(memory_manager.episodic_memory)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowledge-check-module2",
   "metadata": {},
   "source": [
    "## 📝 Module 2 Knowledge Check
    "
    "Test your understanding of memory and learning concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowledge-check-code-module2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def module2_knowledge_check():
    "    \"\"\"Interactive knowledge check for Module 2\"\"\"
    "    
    "    questions = [
    "        {
    "            "question": \"What are the four main types of memory in advanced agentic systems?\",
    "            "options": [
    "                \"A) Short, Medium, Long, Permanent\",
    "                \"B) Working, Episodic, Semantic, Procedural\",
    "                \"C) Input, Process, Output, Feedback\",
    "                \"D) User, System, Context, Historical\"
    "            ],
    "            "correct": \"B\",
    "            "explanation": \"Working memory holds current context, Episodic stores experiences, Semantic contains knowledge, and Procedural holds skills.\"
    "        },
    "        {
    "            "question": \"Why is memory consolidation important for agents?\",
    "            "options": [
    "                \"A) To save storage space only\",
    "                \"B) To improve retrieval speed\",
    "                \"C) To merge similar memories, promote important ones, and archive low-value memories\",
    "                \"D) To delete all old memories\"
    "            ],
    "            "correct": \"C\",
    "            "explanation": \"Consolidation optimizes memory by organizing, prioritizing, and managing memory resources effectively.\"
    "        },
    "        {
    "            "question": \"How do learning agents improve their performance over time?\",
    "            "options": [
    "                \"A) By getting faster processors\",
    "                \"B) By storing experiences, learning patterns, and adapting behavior based on outcomes\",
    "                \"C) By using more API calls\",
    "                \"D) By increasing memory size only\"
    "            ],
    "            "correct": \"B\",
    "            "explanation": \"Learning agents improve through experience analysis, pattern recognition, and behavioral adaptation.\"
    "        },
    "        {
    "            "question": \"What is the purpose of user preference learning in agents?\",
    "            "options": [
    "                \"A) To spy on users\",
    "                \"B) To personalize interactions and improve user experience\",
    "                \"C) To reduce computational costs\",
    "                \"D) To make agents more complex\"
    "            ],
    "            "correct": \"B\",
    "            "explanation": \"User preference learning enables personalized, contextually appropriate interactions that improve user satisfaction.\"
    "        },
    "    ]
    "    
    "    print(\"📝 MODULE 2 KNOWLEDGE CHECK\")
    "    print(\"=\" * 40)
    "    
    "    score = 0
    "    for i, q in enumerate(questions, 1):
    "        print(f\"\\nQuestion {i}: {q['question']}\")
    "        for option in q['options']:
    "            print(f\"  {option}\")
    "        
    "        print(f\"\\n✅ Correct Answer: {q['correct']}\")
    "        print(f\"💡 Explanation: {q['explanation']}\")
    "        score += 1
    "    
    "    print(f\"\\n🎯 Knowledge check complete!\")
    "    print(f\"📊 Understanding level: {score}/{len(questions)} concepts covered\")
    "
    "module2_knowledge_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module2-summary",
   "metadata": {},
   "source": [
    "## 🎯 Module 2 Summary
    "
    "Excellent work! You've built sophisticated memory and learning systems for agentic AI. Let's review your accomplishments:
    "
    "### ✅ What You Built:
    "- **Advanced Memory Architecture** with multiple memory types
    "- **Learning Agent** that improves through experience
    "- **Smart Tools** that learn from usage patterns
    "- **Memory Consolidation System** for optimization
    "- **Personalization Engine** that adapts to user preferences
    "
    "### 🧠 Key Concepts Mastered:
    "- **Memory Types**: Working, Episodic, Semantic, Procedural
    "- **Learning Mechanisms**: Experience analysis, pattern extraction
    "- **Memory Retrieval**: Relevance scoring, context-aware search
    "- **User Personalization**: Preference learning and adaptation
    "- **Memory Management**: Consolidation, promotion, archival
    "
    "### 🚀 Next Steps:
    "In Module 3, you'll learn to:
    "- Integrate agents with external tools and APIs
    "- Handle complex, multi-step workflows
    "- Build robust error handling and recovery
    "- Create production-ready tool integration systems
    "
    "### 💪 Challenge Exercises (Optional):
    "Before Module 3, try:
    "1. Implementing semantic similarity using embeddings
    "2. Creating a memory compression system
    "3. Building a multi-user memory isolation system
    "4. Adding emotion and sentiment tracking to memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "module2-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Module 2 Progress Summary
    "def module2_progress_summary():
    "    print(\"📈 MODULE 2 PROGRESS SUMMARY\")
    "    print(\"=\" * 40)
    "    
    "    capabilities = [
    "        \"✅ Advanced memory architecture (4 types)\",
    "        \"✅ Experience-based learning system\",
    "        \"✅ User preference tracking\", 
    "        \"✅ Memory consolidation and optimization\",
    "        \"✅ Context-aware conversation handling\",
    "        \"✅ Smart tool development\",
    "        \"✅ Memory visualization and analysis\"
    "    ]
    "    
    "    print(\"\\n🧠 Memory & Learning Capabilities:\")
    "    for cap in capabilities:
    "        print(f\"  {cap}\")
    "    
    "    # Get final statistics
    "    final_stats = learning_agent.get_learning_statistics()
    "    
    "    print(f\"\\n📊 Final Agent Statistics:\")
    "    print(f\"  • Total memories: {final_stats['total_memories']}\")
    "    print(f\"  • Conversations: {final_stats['conversations_held']}\")
    "    print(f\"  • Learning events: {final_stats['learning_events']}\")
    "    print(f\"  • Users tracked: {final_stats['users_tracked']}\")
    "    print(f\"  • Memory retrieval success: {final_stats['retrieval_success_rate']:.1f}%\")
    "    
    "    print(f\"\\n🎯 Ready for Module 3: Tool Integration and Environment Interaction!\")
    "    print(f\"\\n💡 Pro Tip: The memory system you built will be crucial for coordinating complex multi-step tasks!\")
    "
    "module2_progress_summary()"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": \"Python 3\",
   "language": \"python\",
   "name": \"python3\"
  },
  "language_info": {
   "codemirror_mode": {
    "name": \"ipython\",
    "version": 3
   },
   "file_extension": \".py\",
   "mimetype": \"text/x-python\",
   "name": \"python\",
   "nbconvert_exporter": \"python\",
   "pygments_lexer": \"ipython3\",
   "version": \"3.8.0\"
  }\n }\n}