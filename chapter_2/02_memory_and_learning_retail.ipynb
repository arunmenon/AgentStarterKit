{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Memory and Learning Systems üß†\n",
    "*Building Retail AI Agents That Remember and Improve*\n",
    "\n",
    "**Duration**: 50 minutes  \n",
    "**Level**: Intermediate  \n",
    "**Domain**: Retail Operations (Walmart)\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this module, you'll understand:\n",
    "\n",
    "1. **Memory Architecture**: Four types of memory systems for retail AI\n",
    "2. **Working Memory**: Real-time inventory and customer interactions\n",
    "3. **Episodic Memory**: Learning from past sales events and seasons\n",
    "4. **Semantic Memory**: Product knowledge and store operations\n",
    "5. **Procedural Memory**: Optimized workflows and best practices\n",
    "6. **LLM Integration**: Using Ollama for intelligent memory retrieval\n",
    "7. **Adaptive Learning**: Improving from Black Friday to everyday ops\n",
    "\n",
    "## üè™ Retail Context\n",
    "\n",
    "Imagine you're building an AI assistant for Walmart that:\n",
    "- Remembers customer shopping patterns\n",
    "- Learns from seasonal trends\n",
    "- Optimizes inventory management\n",
    "- Improves store operations\n",
    "- Adapts to local market conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Understanding Memory Types in Retail\n",
    "\n",
    "### 1. **Working Memory** (Current Operations)\n",
    "- Active customer in store needing help\n",
    "- Current inventory levels and alerts\n",
    "- Today's promotions and pricing\n",
    "- Real-time store traffic\n",
    "\n",
    "### 2. **Episodic Memory** (Past Events)\n",
    "- Last year's Black Friday performance\n",
    "- Successful product launches\n",
    "- Customer complaint resolutions\n",
    "- Seasonal shopping patterns\n",
    "\n",
    "### 3. **Semantic Memory** (Retail Knowledge)\n",
    "- Product specifications and relationships\n",
    "- Store layout and department info\n",
    "- Supplier details and lead times\n",
    "- Walmart policies and procedures\n",
    "\n",
    "### 4. **Procedural Memory** (How-To Skills)\n",
    "- Inventory reordering workflows\n",
    "- Customer service protocols\n",
    "- Price matching procedures\n",
    "- Seasonal transition strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Ollama LLM (matching Module 1)\n",
    "MODEL_NAME = \"qwen2.5:7b-instruct-q4_K_M\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Core imports\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from collections import deque, defaultdict\n",
    "from enum import Enum\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Test Ollama connection\n",
    "try:\n",
    "    response = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Ollama server is running\")\n",
    "        models = response.json().get('models', [])\n",
    "        model_names = [model['name'] for model in models]\n",
    "        if MODEL_NAME in model_names:\n",
    "            print(f\"‚úÖ {MODEL_NAME} is available for intelligent memory operations\")\n",
    "            OLLAMA_AVAILABLE = True\n",
    "        else:\n",
    "            print(f\"‚ùå {MODEL_NAME} not found. Run: ollama pull qwen2.5:7b-instruct-q4_K_M\")\n",
    "            OLLAMA_AVAILABLE = False\n",
    "    else:\n",
    "        print(f\"‚ùå Ollama server responded with status {response.status_code}\")\n",
    "        OLLAMA_AVAILABLE = False\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Cannot connect to Ollama. Memory system will use basic operations.\")\n",
    "    print(\"To enable intelligent memory, run: ollama serve\")\n",
    "    OLLAMA_AVAILABLE = False\n",
    "\n",
    "print(\"\\nüè™ Walmart Retail AI Memory System Ready!\")\n",
    "print(\"üìç Location: Bentonville, AR Supercenter #100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Part 1: Memory Architecture\n",
    "\n",
    "Let's build a comprehensive memory system from the ground up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define memory types for retail context\n",
    "class MemoryType(Enum):\n",
    "    \"\"\"Types of memory in our retail AI system\"\"\"\n",
    "    WORKING = \"working\"      # Current store state\n",
    "    EPISODIC = \"episodic\"    # Past events and outcomes\n",
    "    SEMANTIC = \"semantic\"    # Product and policy knowledge\n",
    "    PROCEDURAL = \"procedural\" # Operational workflows\n",
    "\n",
    "@dataclass\n",
    "class RetailMemoryItem:\n",
    "    \"\"\"Base class for all retail memory items\"\"\"\n",
    "    content: Any                    # The memory content\n",
    "    timestamp: datetime             # When it occurred\n",
    "    importance: float               # Business impact (0-1)\n",
    "    department: str = \"General\"     # Which department\n",
    "    store_id: str = \"#100\"         # Which store\n",
    "    access_count: int = 0          # How often referenced\n",
    "    last_accessed: Optional[datetime] = None\n",
    "    decay_rate: float = 0.1        # How fast it becomes less relevant\n",
    "    memory_type: MemoryType = MemoryType.EPISODIC\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def access(self):\n",
    "        \"\"\"Update access statistics\"\"\"\n",
    "        self.access_count += 1\n",
    "        self.last_accessed = datetime.now()\n",
    "        # Accessing reinforces memory importance\n",
    "        self.importance = min(1.0, self.importance * 1.1)\n",
    "    \n",
    "    def get_strength(self) -> float:\n",
    "        \"\"\"Calculate memory strength using Ebbinghaus forgetting curve\"\"\"\n",
    "        if not self.last_accessed:\n",
    "            self.last_accessed = self.timestamp\n",
    "            \n",
    "        time_since_access = (datetime.now() - self.last_accessed).total_seconds()\n",
    "        hours_passed = time_since_access / 3600\n",
    "        \n",
    "        # Ebbinghaus forgetting curve: R = e^(-t/S)\n",
    "        # Where S is stability (affected by importance and access count)\n",
    "        stability = (1 + self.importance) * (1 + math.log1p(self.access_count))\n",
    "        retention = math.exp(-hours_passed / (stability * 24))  # 24 hours base stability\n",
    "        \n",
    "        # Apply importance weighting\n",
    "        strength = retention * self.importance\n",
    "        \n",
    "        # Boost for recent access (recency effect)\n",
    "        if hours_passed < 1:\n",
    "            strength *= 1.2\n",
    "        elif hours_passed < 24:\n",
    "            strength *= 1.1\n",
    "            \n",
    "        # Boost for frequently accessed items (frequency effect)\n",
    "        if self.access_count > 5:\n",
    "            strength *= 1.1\n",
    "        elif self.access_count > 10:\n",
    "            strength *= 1.2\n",
    "            \n",
    "        return min(1.0, strength)\n",
    "\n",
    "@dataclass\n",
    "class RetailEpisode(RetailMemoryItem):\n",
    "    \"\"\"Memory of a specific retail event\"\"\"\n",
    "    event_type: str = \"\"           # sale, return, complaint, etc.\n",
    "    products_involved: List[str] = field(default_factory=list)\n",
    "    customer_segment: str = \"\"     # regular, premium, new\n",
    "    outcome: str = \"\"              # What happened\n",
    "    revenue_impact: float = 0.0    # Dollar impact\n",
    "    success: bool = True           # Was it successful?\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.memory_type = MemoryType.EPISODIC\n",
    "\n",
    "@dataclass\n",
    "class ProductKnowledge(RetailMemoryItem):\n",
    "    \"\"\"Semantic memory about products and categories\"\"\"\n",
    "    product_id: str = \"\"           # SKU or product ID\n",
    "    category: str = \"\"             # Product category\n",
    "    relations: Dict[str, List[str]] = field(default_factory=dict)  # Related products\n",
    "    attributes: Dict[str, Any] = field(default_factory=dict)  # Price, features, etc.\n",
    "    supplier_info: Dict[str, Any] = field(default_factory=dict)\n",
    "    confidence: float = 1.0        # How accurate this info is\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.memory_type = MemoryType.SEMANTIC\n",
    "\n",
    "@dataclass \n",
    "class RetailProcedure(RetailMemoryItem):\n",
    "    \"\"\"Memory of retail operational procedures\"\"\"\n",
    "    procedure_name: str = \"\"       # What procedure\n",
    "    trigger_conditions: List[str] = field(default_factory=list)  # When to use\n",
    "    steps: List[str] = field(default_factory=list)  # How to execute\n",
    "    success_rate: float = 0.0      # Historical effectiveness\n",
    "    execution_count: int = 0       # Times used\n",
    "    average_time: float = 0.0      # Minutes to complete\n",
    "    cost_savings: float = 0.0      # Average $ saved/earned\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.memory_type = MemoryType.PROCEDURAL\n",
    "        \n",
    "    def update_performance(self, success: bool, time_taken: float, savings: float = 0):\n",
    "        \"\"\"Update procedure performance metrics\"\"\"\n",
    "        self.execution_count += 1\n",
    "        # Running average for success rate\n",
    "        self.success_rate = ((self.success_rate * (self.execution_count - 1)) + \n",
    "                           (1.0 if success else 0.0)) / self.execution_count\n",
    "        # Running average for time\n",
    "        self.average_time = ((self.average_time * (self.execution_count - 1)) + \n",
    "                           time_taken) / self.execution_count\n",
    "        # Track cost savings\n",
    "        self.cost_savings = ((self.cost_savings * (self.execution_count - 1)) + \n",
    "                           savings) / self.execution_count\n",
    "\n",
    "@dataclass\n",
    "class CustomerInteraction(RetailMemoryItem):\n",
    "    \"\"\"Special episodic memory for customer interactions\"\"\"\n",
    "    interaction_type: str = \"\"     # inquiry, complaint, praise\n",
    "    customer_mood: str = \"\"        # happy, frustrated, neutral\n",
    "    resolution: str = \"\"           # How it was resolved\n",
    "    satisfaction_score: float = 0.0  # 1-5 rating\n",
    "    associate_id: str = \"\"         # Who helped\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.memory_type = MemoryType.EPISODIC\n",
    "        # Customer interactions are always important\n",
    "        self.importance = max(0.7, self.importance)\n",
    "\n",
    "print(\"‚úÖ Retail memory structures defined!\")\n",
    "print(f\"Memory types: {[t.value for t in MemoryType]}\")\n",
    "print(\"\\nüè™ Specialized for Walmart operations:\")\n",
    "print(\"  - Product relationships and inventory\")\n",
    "print(\"  - Customer interaction tracking\")\n",
    "print(\"  - Procedural efficiency metrics\")\n",
    "print(\"  - Revenue impact analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Part 2: LLM Integration for Intelligent Memory\n",
    "\n",
    "Using Ollama to enhance memory retrieval and consolidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaLLM:\n",
    "    \"\"\"LLM interface for intelligent memory operations\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = MODEL_NAME, temperature: float = 0.7):\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.base_url = OLLAMA_BASE_URL\n",
    "        self.available = OLLAMA_AVAILABLE\n",
    "        \n",
    "    def generate(self, prompt: str, system: str = \"\") -> str:\n",
    "        \"\"\"Generate response from LLM\"\"\"\n",
    "        if not self.available:\n",
    "            return \"LLM not available\"\n",
    "            \n",
    "        full_prompt = f\"{system}\\n\\nUser: {prompt}\\n\\nAssistant:\" if system else prompt\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/api/generate\",\n",
    "                json={\n",
    "                    \"model\": self.model,\n",
    "                    \"prompt\": full_prompt,\n",
    "                    \"temperature\": self.temperature,\n",
    "                    \"stream\": False\n",
    "                },\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json().get('response', '')\n",
    "            else:\n",
    "                return f\"Error: {response.status_code}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def analyze_memory_relevance(self, query: str, memory_content: str) -> float:\n",
    "        \"\"\"Use LLM to score memory relevance (0-1)\"\"\"\n",
    "        if not self.available:\n",
    "            return 0.5  # Default relevance\n",
    "            \n",
    "        prompt = f\"\"\"Rate the relevance of this memory to the query on a scale of 0-10.\n",
    "        Query: {query}\n",
    "        Memory: {memory_content}\n",
    "        \n",
    "        Only respond with a number 0-10.\"\"\"\n",
    "        \n",
    "        response = self.generate(prompt)\n",
    "        try:\n",
    "            # Extract number from response\n",
    "            numbers = re.findall(r'\\d+', response)\n",
    "            if numbers:\n",
    "                score = min(10, max(0, int(numbers[0]))) / 10.0\n",
    "                return score\n",
    "        except:\n",
    "            pass\n",
    "        return 0.5  # Default relevance\n",
    "    \n",
    "    def extract_query_intent(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract intent from query\"\"\"\n",
    "        if not self.available:\n",
    "            return {\"department\": \"General\", \"type\": \"general\", \"urgency\": \"medium\"}\n",
    "            \n",
    "        prompt = f\"\"\"Analyze this retail query and extract key intent:\n",
    "        Query: {query}\n",
    "        \n",
    "        Identify:\n",
    "        1. Department (Electronics, Grocery, etc.)\n",
    "        2. Type (product, procedure, customer service, etc.)\n",
    "        3. Urgency (high, medium, low)\n",
    "        \n",
    "        Be concise.\"\"\"\n",
    "        \n",
    "        response = self.generate(prompt)\n",
    "        \n",
    "        # Simple parsing\n",
    "        intent = {\n",
    "            \"department\": \"General\",\n",
    "            \"type\": \"general\",\n",
    "            \"urgency\": \"medium\"\n",
    "        }\n",
    "        \n",
    "        # Extract department\n",
    "        for dept in [\"Electronics\", \"Grocery\", \"Apparel\", \"Pharmacy\", \"Operations\"]:\n",
    "            if dept.lower() in response.lower():\n",
    "                intent[\"department\"] = dept\n",
    "                break\n",
    "                \n",
    "        return intent\n",
    "\n",
    "print(\"‚úÖ LLM interface ready for intelligent memory operations\")\n",
    "print(f\"ü§ñ LLM Available: {OLLAMA_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Part 3: Walmart Memory Manager\n",
    "\n",
    "A sophisticated memory system with LLM-enhanced retrieval and consolidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalmartMemoryManager:\n",
    "    \"\"\"Manages retail memories with business intelligence and LLM integration\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 store_id: str = \"#100\",\n",
    "                 working_memory_size: int = 10,\n",
    "                 consolidation_threshold: float = 0.7,\n",
    "                 use_llm: bool = True):\n",
    "        self.store_id = store_id\n",
    "        self.consolidation_threshold = consolidation_threshold\n",
    "        self.use_llm = use_llm and OLLAMA_AVAILABLE\n",
    "        \n",
    "        # Initialize LLM if available\n",
    "        if self.use_llm:\n",
    "            self.llm = OllamaLLM()\n",
    "            print(\"ü§ñ LLM-enhanced memory operations enabled\")\n",
    "        else:\n",
    "            print(\"üìù Using basic memory operations (no LLM)\")\n",
    "        \n",
    "        # Working memory - limited size queue\n",
    "        self.working_memory = deque(maxlen=working_memory_size)\n",
    "        \n",
    "        # Long-term memories\n",
    "        self.episodes: List[RetailEpisode] = []\n",
    "        self.product_knowledge: Dict[str, ProductKnowledge] = {}\n",
    "        self.procedures: Dict[str, RetailProcedure] = {}\n",
    "        self.customer_interactions: List[CustomerInteraction] = []\n",
    "        \n",
    "        # Indices for fast retrieval\n",
    "        self.product_index = defaultdict(list)  # category -> products\n",
    "        self.seasonal_index = defaultdict(list)  # season -> episodes\n",
    "        self.department_index = defaultdict(list)  # dept -> memories\n",
    "        \n",
    "        # Business metrics\n",
    "        self.total_revenue_impact = 0.0\n",
    "        self.customer_satisfaction_avg = 4.0\n",
    "        self.total_memories = 0\n",
    "        \n",
    "        # Initialize with some Walmart knowledge\n",
    "        self._initialize_walmart_knowledge()\n",
    "    \n",
    "    def add_to_working_memory(self, item: Any):\n",
    "        \"\"\"Add item to working memory with intelligent consolidation\"\"\"\n",
    "        self.working_memory.append(item)\n",
    "        \n",
    "        # Automatic consolidation based on importance threshold\n",
    "        if isinstance(item, RetailMemoryItem):\n",
    "            # Check consolidation threshold\n",
    "            if item.importance >= self.consolidation_threshold:\n",
    "                print(f\"  üíæ Auto-consolidating to long-term memory (importance: {item.importance:.2f})\")\n",
    "                self._consolidate_memory(item)\n",
    "            \n",
    "            # Also consolidate if working memory is getting full\n",
    "            elif len(self.working_memory) >= self.working_memory.maxlen - 2:\n",
    "                # Find most important items to consolidate\n",
    "                memory_items = [m for m in self.working_memory if isinstance(m, RetailMemoryItem)]\n",
    "                if memory_items:\n",
    "                    memory_items.sort(key=lambda m: m.importance, reverse=True)\n",
    "                    for mem in memory_items[:3]:  # Consolidate top 3\n",
    "                        if mem.importance >= self.consolidation_threshold * 0.8:\n",
    "                            self._consolidate_memory(mem)\n",
    "    \n",
    "    def _consolidate_memory(self, memory: RetailMemoryItem):\n",
    "        \"\"\"Move important memories from working to long-term storage\"\"\"\n",
    "        if isinstance(memory, RetailEpisode):\n",
    "            self.episodes.append(memory)\n",
    "            # Index by context words\n",
    "            for word in memory.outcome.lower().split():\n",
    "                self.seasonal_index[word].append(memory)\n",
    "                \n",
    "        elif isinstance(memory, ProductKnowledge):\n",
    "            # Merge with existing knowledge if exists\n",
    "            if memory.product_id in self.product_knowledge:\n",
    "                existing = self.product_knowledge[memory.product_id]\n",
    "                # Merge relations\n",
    "                for rel_type, concepts in memory.relations.items():\n",
    "                    if rel_type in existing.relations:\n",
    "                        existing.relations[rel_type].extend(concepts)\n",
    "                    else:\n",
    "                        existing.relations[rel_type] = concepts\n",
    "                # Update confidence (weighted average)\n",
    "                total_weight = existing.importance + memory.importance\n",
    "                existing.confidence = ((existing.confidence * existing.importance + \n",
    "                                      memory.confidence * memory.importance) / total_weight)\n",
    "                existing.importance = min(1.0, existing.importance + 0.1)\n",
    "            else:\n",
    "                self.product_knowledge[memory.product_id] = memory\n",
    "                self.product_index[memory.category].append(memory.product_id)\n",
    "                        \n",
    "        elif isinstance(memory, RetailProcedure):\n",
    "            # Merge with existing procedure if exists\n",
    "            if memory.procedure_name in self.procedures:\n",
    "                existing = self.procedures[memory.procedure_name]\n",
    "                # Keep the more successful procedure\n",
    "                if memory.success_rate > existing.success_rate:\n",
    "                    self.procedures[memory.procedure_name] = memory\n",
    "            else:\n",
    "                self.procedures[memory.procedure_name] = memory\n",
    "                \n",
    "        elif isinstance(memory, CustomerInteraction):\n",
    "            self.customer_interactions.append(memory)\n",
    "        \n",
    "        self.total_memories += 1\n",
    "    \n",
    "    def retrieve_relevant_memories(self, query: str, context: Dict[str, Any] = None,\n",
    "                                 limit: int = 5) -> List[RetailMemoryItem]:\n",
    "        \"\"\"Retrieve memories with intelligent relevance scoring\"\"\"\n",
    "        print(f\"\\nüîç Retrieving memories for: '{query}'\")\n",
    "        \n",
    "        # Extract query intent using LLM if available\n",
    "        query_intent = {}\n",
    "        if self.use_llm:\n",
    "            query_intent = self.llm.extract_query_intent(query)\n",
    "            print(f\"  üìä Intent: {query_intent}\")\n",
    "        \n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Score all memories\n",
    "        scored_memories = []\n",
    "        \n",
    "        # Score episodes\n",
    "        for episode in self.episodes:\n",
    "            score = self._score_memory_relevance(episode, query, query_intent)\n",
    "            if score > 0.1:  # Threshold\n",
    "                scored_memories.append((episode, score))\n",
    "        \n",
    "        # Score product knowledge\n",
    "        for product_id, knowledge in self.product_knowledge.items():\n",
    "            score = self._score_memory_relevance(knowledge, query, query_intent)\n",
    "            if score > 0.1:\n",
    "                scored_memories.append((knowledge, score))\n",
    "        \n",
    "        # Score procedures\n",
    "        for proc_name, procedure in self.procedures.items():\n",
    "            score = self._score_memory_relevance(procedure, query, query_intent)\n",
    "            if score > 0.1:\n",
    "                scored_memories.append((procedure, score))\n",
    "        \n",
    "        # Score recent customer interactions\n",
    "        for interaction in self.customer_interactions[-10:]:\n",
    "            score = self._score_memory_relevance(interaction, query, query_intent)\n",
    "            if score > 0.1:\n",
    "                scored_memories.append((interaction, score))\n",
    "        \n",
    "        # Sort by combined score (relevance * strength)\n",
    "        scored_memories.sort(key=lambda x: x[1] * x[0].get_strength(), reverse=True)\n",
    "        \n",
    "        # Get top memories and update access\n",
    "        top_memories = []\n",
    "        for memory, score in scored_memories[:limit]:\n",
    "            memory.access()\n",
    "            top_memories.append(memory)\n",
    "            print(f\"  ‚úì Retrieved: {memory.content[:50]}... (relevance: {score:.2f})\")\n",
    "        \n",
    "        return top_memories\n",
    "    \n",
    "    def _score_memory_relevance(self, memory: RetailMemoryItem, query: str, \n",
    "                               intent: Dict[str, Any]) -> float:\n",
    "        \"\"\"Score memory relevance using multiple factors\"\"\"\n",
    "        score = 0.0\n",
    "        query_words = set(query.lower().split())\n",
    "        \n",
    "        # 1. Keyword matching (basic)\n",
    "        if isinstance(memory, RetailEpisode):\n",
    "            # Check products\n",
    "            for product in memory.products_involved:\n",
    "                if any(word in product.lower() for word in query_words):\n",
    "                    score += 0.3\n",
    "            # Check outcome\n",
    "            if any(word in memory.outcome.lower() for word in query_words):\n",
    "                score += 0.2\n",
    "                \n",
    "        elif isinstance(memory, ProductKnowledge):\n",
    "            if any(word in memory.product_id.lower() for word in query_words):\n",
    "                score += 0.4\n",
    "            if any(word in memory.category.lower() for word in query_words):\n",
    "                score += 0.3\n",
    "                \n",
    "        elif isinstance(memory, RetailProcedure):\n",
    "            if any(word in memory.procedure_name.lower() for word in query_words):\n",
    "                score += 0.5\n",
    "            # Check trigger conditions\n",
    "            for trigger in memory.trigger_conditions:\n",
    "                if any(word in trigger.lower() for word in query_words):\n",
    "                    score += 0.2\n",
    "                    \n",
    "        # 2. Department matching\n",
    "        if intent.get(\"department\") == memory.department:\n",
    "            score += 0.2\n",
    "            \n",
    "        # 3. LLM-based semantic similarity (if available)\n",
    "        if self.use_llm and score > 0:\n",
    "            llm_score = self.llm.analyze_memory_relevance(query, memory.content)\n",
    "            score = (score + llm_score) / 2  # Average with LLM score\n",
    "            \n",
    "        # 4. Recency boost for customer interactions\n",
    "        if isinstance(memory, CustomerInteraction):\n",
    "            hours_old = (datetime.now() - memory.timestamp).total_seconds() / 3600\n",
    "            if hours_old < 24:\n",
    "                score *= 1.2\n",
    "                \n",
    "        # 5. Success/failure relevance\n",
    "        if \"problem\" in query.lower() or \"issue\" in query.lower():\n",
    "            if hasattr(memory, \"success\") and not memory.success:\n",
    "                score *= 1.3  # Boost failed memories for problem queries\n",
    "                \n",
    "        return min(1.0, score)\n",
    "    \n",
    "    def _initialize_walmart_knowledge(self):\n",
    "        \"\"\"Pre-load essential Walmart operational knowledge\"\"\"\n",
    "        # Price match procedure\n",
    "        price_match = RetailProcedure(\n",
    "            content=\"Walmart Price Match Guarantee procedure\",\n",
    "            timestamp=datetime.now(),\n",
    "            importance=0.9,\n",
    "            department=\"Customer Service\",\n",
    "            procedure_name=\"price_match\",\n",
    "            trigger_conditions=[\"customer shows lower price\", \"competitor ad\"],\n",
    "            steps=[\n",
    "                \"Verify competitor price on current ad\",\n",
    "                \"Check if item is identical (brand, size, model)\",\n",
    "                \"Confirm competitor has item in stock\",\n",
    "                \"Apply price match at register\",\n",
    "                \"Log price match in system\"\n",
    "            ],\n",
    "            success_rate=0.95,\n",
    "            execution_count=1000,\n",
    "            average_time=3.5,\n",
    "            cost_savings=-5.50  # Average loss per match, but retains customer\n",
    "        )\n",
    "        self.procedures[\"price_match\"] = price_match\n",
    "        \n",
    "        # Black Friday prep procedure\n",
    "        black_friday = RetailProcedure(\n",
    "            content=\"Black Friday preparation workflow\",\n",
    "            timestamp=datetime.now(),\n",
    "            importance=1.0,\n",
    "            department=\"Operations\",\n",
    "            procedure_name=\"black_friday_prep\",\n",
    "            trigger_conditions=[\"2 weeks before Black Friday\"],\n",
    "            steps=[\n",
    "                \"Review last year's sales data and pain points\",\n",
    "                \"Double-check inventory levels for doorbusters\",\n",
    "                \"Schedule extra staff for all departments\",\n",
    "                \"Set up queue management systems\",\n",
    "                \"Prepare online pickup area for increased volume\",\n",
    "                \"Test all POS systems and backups\",\n",
    "                \"Brief staff on crowd control procedures\"\n",
    "            ],\n",
    "            success_rate=0.92,\n",
    "            execution_count=5,\n",
    "            average_time=480,  # 8 hours\n",
    "            cost_savings=125000  # Smooth operations save/earn this much\n",
    "        )\n",
    "        self.procedures[\"black_friday_prep\"] = black_friday\n",
    "        \n",
    "        print(\"üìö Loaded Walmart operational procedures\")\n",
    "    \n",
    "    # [Continue with all other methods from the original: remember_sale, remember_customer_interaction, etc.]\n",
    "    \n",
    "    def remember_sale(self, products: List[str], amount: float, \n",
    "                     customer_type: str = \"regular\", special_event: str = \"\"):\n",
    "        \"\"\"Store memory of a sale transaction\"\"\"\n",
    "        episode = RetailEpisode(\n",
    "            content=f\"Sale of {len(products)} items for ${amount:.2f}\",\n",
    "            timestamp=datetime.now(),\n",
    "            importance=min(1.0, amount / 1000),  # Higher sales more important\n",
    "            department=self._get_department(products[0] if products else \"General\"),\n",
    "            event_type=\"sale\",\n",
    "            products_involved=products,\n",
    "            customer_segment=customer_type,\n",
    "            outcome=f\"Completed sale ${amount:.2f}\",\n",
    "            revenue_impact=amount,\n",
    "            success=True\n",
    "        )\n",
    "        \n",
    "        if special_event:\n",
    "            episode.metadata[\"event\"] = special_event\n",
    "            self.seasonal_index[special_event].append(episode)\n",
    "            \n",
    "        self.add_to_working_memory(episode)\n",
    "        self.total_revenue_impact += amount\n",
    "        \n",
    "        # Update product relationships\n",
    "        if len(products) > 1:\n",
    "            self._update_product_relationships(products)\n",
    "            \n",
    "        return episode\n",
    "    \n",
    "    def remember_customer_interaction(self, interaction_type: str, \n",
    "                                    department: str, resolution: str,\n",
    "                                    satisfaction: float, mood: str = \"neutral\"):\n",
    "        \"\"\"Store customer service interaction\"\"\"\n",
    "        interaction = CustomerInteraction(\n",
    "            content=f\"{interaction_type} in {department}: {resolution}\",\n",
    "            timestamp=datetime.now(),\n",
    "            importance=0.8 if interaction_type == \"complaint\" else 0.6,\n",
    "            department=department,\n",
    "            interaction_type=interaction_type,\n",
    "            customer_mood=mood,\n",
    "            resolution=resolution,\n",
    "            satisfaction_score=satisfaction,\n",
    "            associate_id=f\"A{random.randint(1000, 9999)}\"\n",
    "        )\n",
    "        \n",
    "        self.add_to_working_memory(interaction)\n",
    "        \n",
    "        # Update satisfaction average\n",
    "        total_interactions = len(self.customer_interactions)\n",
    "        self.customer_satisfaction_avg = (\n",
    "            (self.customer_satisfaction_avg * total_interactions + satisfaction) \n",
    "            / (total_interactions + 1)\n",
    "        )\n",
    "        \n",
    "        return interaction\n",
    "    \n",
    "    def learn_product_fact(self, product_id: str, category: str, \n",
    "                          attributes: Dict, relations: Dict[str, List[str]] = None):\n",
    "        \"\"\"Store product knowledge\"\"\"\n",
    "        knowledge = ProductKnowledge(\n",
    "            content=f\"Product {product_id} in {category}\",\n",
    "            timestamp=datetime.now(),\n",
    "            importance=0.7,\n",
    "            department=self._get_department(category),\n",
    "            product_id=product_id,\n",
    "            category=category,\n",
    "            attributes=attributes,\n",
    "            relations=relations or {},\n",
    "            confidence=0.95\n",
    "        )\n",
    "        \n",
    "        self.add_to_working_memory(knowledge)\n",
    "        return knowledge\n",
    "    \n",
    "    def _get_department(self, item: str) -> str:\n",
    "        \"\"\"Map items to Walmart departments\"\"\"\n",
    "        dept_map = {\n",
    "            \"grocery\": \"Grocery\",\n",
    "            \"electronics\": \"Electronics\",\n",
    "            \"apparel\": \"Apparel\",\n",
    "            \"home\": \"Home & Garden\",\n",
    "            \"pharmacy\": \"Pharmacy\",\n",
    "            \"auto\": \"Auto Care\",\n",
    "            \"toys\": \"Toys\",\n",
    "            \"sports\": \"Sports & Outdoors\"\n",
    "        }\n",
    "        \n",
    "        item_lower = item.lower()\n",
    "        for key, dept in dept_map.items():\n",
    "            if key in item_lower:\n",
    "                return dept\n",
    "        return \"General Merchandise\"\n",
    "    \n",
    "    def _update_product_relationships(self, products: List[str]):\n",
    "        \"\"\"Learn which products are frequently bought together\"\"\"\n",
    "        for i, product1 in enumerate(products):\n",
    "            if product1 in self.product_knowledge:\n",
    "                knowledge = self.product_knowledge[product1]\n",
    "                if \"frequently_bought_with\" not in knowledge.relations:\n",
    "                    knowledge.relations[\"frequently_bought_with\"] = []\n",
    "                    \n",
    "                for product2 in products[i+1:]:\n",
    "                    if product2 not in knowledge.relations[\"frequently_bought_with\"]:\n",
    "                        knowledge.relations[\"frequently_bought_with\"].append(product2)\n",
    "    \n",
    "    def get_department_insights(self, department: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get insights for a specific department\"\"\"\n",
    "        dept_episodes = [e for e in self.episodes if e.department == department]\n",
    "        \n",
    "        if not dept_episodes:\n",
    "            return {\"message\": f\"No data for {department}\"}\n",
    "            \n",
    "        total_revenue = sum(e.revenue_impact for e in dept_episodes)\n",
    "        avg_transaction = total_revenue / len(dept_episodes) if dept_episodes else 0\n",
    "        \n",
    "        # Find best selling products\n",
    "        product_sales = defaultdict(int)\n",
    "        for episode in dept_episodes:\n",
    "            for product in episode.products_involved:\n",
    "                product_sales[product] += 1\n",
    "                \n",
    "        top_products = sorted(product_sales.items(), \n",
    "                            key=lambda x: x[1], reverse=True)[:5]\n",
    "        \n",
    "        return {\n",
    "            \"department\": department,\n",
    "            \"total_revenue\": total_revenue,\n",
    "            \"transaction_count\": len(dept_episodes),\n",
    "            \"avg_transaction_size\": avg_transaction,\n",
    "            \"top_products\": top_products,\n",
    "            \"time_range\": {\n",
    "                \"earliest\": min(e.timestamp for e in dept_episodes),\n",
    "                \"latest\": max(e.timestamp for e in dept_episodes)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def visualize_retail_intelligence(self):\n",
    "        \"\"\"Create retail-specific memory visualizations\"\"\"\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle(f'Walmart Store {self.store_id} Memory Analytics', fontsize=16)\n",
    "        \n",
    "        # Department revenue distribution\n",
    "        dept_revenue = defaultdict(float)\n",
    "        for episode in self.episodes:\n",
    "            if episode.revenue_impact > 0:\n",
    "                dept_revenue[episode.department] += episode.revenue_impact\n",
    "                \n",
    "        if dept_revenue:\n",
    "            depts, revenues = zip(*dept_revenue.items())\n",
    "            ax1.pie(revenues, labels=depts, autopct='%1.1f%%', startangle=90)\n",
    "            ax1.set_title(\"Revenue by Department\")\n",
    "        \n",
    "        # Customer satisfaction trend\n",
    "        if self.customer_interactions:\n",
    "            interactions = self.customer_interactions[-20:]  # Last 20\n",
    "            satisfaction_scores = [i.satisfaction_score for i in interactions]\n",
    "            ax2.plot(satisfaction_scores, marker='o', linewidth=2, markersize=8)\n",
    "            ax2.axhline(y=4.0, color='g', linestyle='--', label='Target (4.0)')\n",
    "            ax2.set_xlabel(\"Recent Interactions\")\n",
    "            ax2.set_ylabel(\"Satisfaction Score\")\n",
    "            ax2.set_title(\"Customer Satisfaction Trend\")\n",
    "            ax2.set_ylim(1, 5)\n",
    "            ax2.legend()\n",
    "        \n",
    "        # Procedure effectiveness\n",
    "        if self.procedures:\n",
    "            procs = list(self.procedures.values())\n",
    "            proc_names = [p.procedure_name for p in procs]\n",
    "            success_rates = [p.success_rate for p in procs]\n",
    "            savings = [p.cost_savings for p in procs]\n",
    "            \n",
    "            x = np.arange(len(proc_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax3.bar(x - width/2, success_rates, width, label='Success Rate')\n",
    "            ax3.set_xlabel('Procedures')\n",
    "            ax3.set_ylabel('Success Rate', color='b')\n",
    "            ax3.set_title('Procedure Performance')\n",
    "            ax3.set_xticks(x)\n",
    "            ax3.set_xticklabels(proc_names, rotation=45, ha='right')\n",
    "            ax3.set_ylim(0, 1.1)\n",
    "            \n",
    "            # Add savings on secondary axis\n",
    "            ax3_twin = ax3.twinx()\n",
    "            ax3_twin.bar(x + width/2, savings, width, label='Avg Savings', color='g')\n",
    "            ax3_twin.set_ylabel('Average Savings ($)', color='g')\n",
    "        \n",
    "        # Time-based activity\n",
    "        if self.episodes:\n",
    "            # Group by hour of day\n",
    "            hour_activity = defaultdict(int)\n",
    "            for episode in self.episodes:\n",
    "                hour = episode.timestamp.hour\n",
    "                hour_activity[hour] += 1\n",
    "                \n",
    "            hours = list(range(24))\n",
    "            activity = [hour_activity.get(h, 0) for h in hours]\n",
    "            \n",
    "            ax4.bar(hours, activity, color='skyblue')\n",
    "            ax4.set_xlabel('Hour of Day')\n",
    "            ax4.set_ylabel('Transaction Count')\n",
    "            ax4.set_title('Store Activity by Hour')\n",
    "            ax4.set_xticks(range(0, 24, 2))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create Walmart memory manager\n",
    "walmart_memory = WalmartMemoryManager(store_id=\"#100\")\n",
    "print(f\"\\n‚úÖ Walmart Memory Manager initialized for Store {walmart_memory.store_id}\")\n",
    "print(f\"üìä Customer satisfaction baseline: {walmart_memory.customer_satisfaction_avg:.1f}/5.0\")\n",
    "print(f\"üìã Pre-loaded procedures: {list(walmart_memory.procedures.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Part 4: Retail Scenarios in Action\n",
    "\n",
    "Let's simulate real Walmart scenarios to see our memory system work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Black Friday Shopping Pattern\n",
    "print(\"üõí Simulating Black Friday 2023...\\n\")\n",
    "\n",
    "# Early morning doorbusters\n",
    "black_friday_sales = [\n",
    "    ([\"Samsung 65in TV\", \"Soundbar\", \"HDMI Cable\"], 899.99, \"deal_hunter\"),\n",
    "    ([\"PS5 Console\", \"Extra Controller\", \"Game Bundle\"], 549.99, \"gamer\"),\n",
    "    ([\"Instant Pot\", \"Air Fryer\", \"Kitchen Scale\"], 129.99, \"regular\"),\n",
    "    ([\"Apple iPad\", \"Apple Pencil\", \"Case\"], 449.99, \"premium\"),\n",
    "    ([\"Kids Bike\", \"Helmet\", \"Training Wheels\"], 89.99, \"family\"),\n",
    "]\n",
    "\n",
    "for products, amount, customer_type in black_friday_sales:\n",
    "    episode = walmart_memory.remember_sale(\n",
    "        products=products,\n",
    "        amount=amount,\n",
    "        customer_type=customer_type,\n",
    "        special_event=\"Black Friday 2023\"\n",
    "    )\n",
    "    print(f\"‚úÖ {episode.content}\")\n",
    "\n",
    "print(f\"\\nüí∞ Total Black Friday revenue so far: ${walmart_memory.total_revenue_impact:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Customer Service Interactions\n",
    "print(\"\\nüë• Customer Service Desk Activity...\\n\")\n",
    "\n",
    "interactions = [\n",
    "    (\"complaint\", \"Electronics\", \"Exchanged defective headphones\", 3.5, \"frustrated\"),\n",
    "    (\"inquiry\", \"Grocery\", \"Located gluten-free products in aisle 7\", 5.0, \"happy\"),\n",
    "    (\"return\", \"Apparel\", \"Processed return without receipt per policy\", 4.0, \"neutral\"),\n",
    "    (\"complaint\", \"Customer Service\", \"Applied price match to competitor ad\", 4.5, \"satisfied\"),\n",
    "    (\"praise\", \"Electronics\", \"Customer thanked associate for TV setup help\", 5.0, \"delighted\"),\n",
    "]\n",
    "\n",
    "for int_type, dept, resolution, satisfaction, mood in interactions:\n",
    "    interaction = walmart_memory.remember_customer_interaction(\n",
    "        interaction_type=int_type,\n",
    "        department=dept,\n",
    "        resolution=resolution,\n",
    "        satisfaction=satisfaction,\n",
    "        mood=mood\n",
    "    )\n",
    "    emoji = \"üòä\" if satisfaction >= 4 else \"üòê\" if satisfaction >= 3 else \"üòû\"\n",
    "    print(f\"{emoji} [{int_type}] {dept}: {resolution} (Score: {satisfaction}/5)\")\n",
    "\n",
    "print(f\"\\nüìà Updated satisfaction average: {walmart_memory.customer_satisfaction_avg:.2f}/5.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: Learning Product Relationships\n",
    "print(\"\\nüì¶ Loading Product Knowledge...\\n\")\n",
    "\n",
    "# Popular products with relationships\n",
    "products = [\n",
    "    (\"TV-SAMSUNG-65-Q80A\", \"Electronics\", \n",
    "     {\"price\": 899.99, \"brand\": \"Samsung\", \"size\": \"65 inch\", \"display\": \"QLED\"},\n",
    "     {\"accessories\": [\"Wall Mount\", \"HDMI Cable\"], \"competes_with\": [\"LG OLED65\"]}),\n",
    "    \n",
    "    (\"FOOD-CEREAL-CHEERIOS\", \"Grocery\",\n",
    "     {\"price\": 3.98, \"brand\": \"General Mills\", \"size\": \"18oz\", \"healthy\": True},\n",
    "     {\"pairs_well\": [\"Milk\", \"Bananas\"], \"alternatives\": [\"Lucky Charms\", \"Corn Flakes\"]}),\n",
    "    \n",
    "    (\"TOY-LEGO-STARWARS\", \"Toys\",\n",
    "     {\"price\": 79.99, \"brand\": \"LEGO\", \"pieces\": 500, \"age_range\": \"8-14\"},\n",
    "     {\"theme_related\": [\"Star Wars Action Figures\", \"SW Lightsaber\"], \"gift_with\": [\"Gift Wrap\"]}),\n",
    "]\n",
    "\n",
    "for product_id, category, attributes, relations in products:\n",
    "    knowledge = walmart_memory.learn_product_fact(\n",
    "        product_id=product_id,\n",
    "        category=category,\n",
    "        attributes=attributes,\n",
    "        relations=relations\n",
    "    )\n",
    "    print(f\"üìö Learned: {product_id} - ${attributes['price']} ({category})\")\n",
    "    print(f\"   Relations: {', '.join(relations.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test memory retrieval with LLM\n",
    "print(\"\\nüîç Testing Intelligent Memory Retrieval...\\n\")\n",
    "\n",
    "queries = [\n",
    "    \"How did Black Friday go?\",\n",
    "    \"Customer complaints in Electronics\",\n",
    "    \"Samsung TV related products\",\n",
    "    \"Price match procedure\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    memories = walmart_memory.retrieve_relevant_memories(query, limit=3)\n",
    "    \n",
    "    if memories:\n",
    "        print(f\"\\nüìå Found {len(memories)} relevant memories\")\n",
    "        for i, memory in enumerate(memories, 1):\n",
    "            if isinstance(memory, RetailEpisode):\n",
    "                print(f\"{i}. [Sale] {memory.content} - Revenue: ${memory.revenue_impact:.2f}\")\n",
    "            elif isinstance(memory, CustomerInteraction):\n",
    "                print(f\"{i}. [Service] {memory.interaction_type}: {memory.resolution}\")\n",
    "            elif isinstance(memory, ProductKnowledge):\n",
    "                print(f\"{i}. [Product] {memory.product_id} - {memory.category}\")\n",
    "            elif isinstance(memory, RetailProcedure):\n",
    "                print(f\"{i}. [Procedure] {memory.procedure_name} - Success: {memory.success_rate:.0%}\")\n",
    "    else:\n",
    "        print(\"   No relevant memories found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize retail intelligence\n",
    "print(\"\\nüìä Generating Retail Intelligence Dashboard...\\n\")\n",
    "walmart_memory.visualize_retail_intelligence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Part 5: Walmart Assistant with Learning\n",
    "\n",
    "An AI assistant that learns from store operations and improves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalmartAssistant:\n",
    "    \"\"\"AI Assistant for Walmart operations with learning capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, store_id: str):\n",
    "        self.name = name\n",
    "        self.store_id = store_id\n",
    "        self.memory = WalmartMemoryManager(store_id=store_id)\n",
    "        self.shift_start = datetime.now()\n",
    "        \n",
    "    def handle_customer_query(self, query: str, department: str = \"General\"):\n",
    "        \"\"\"Process customer queries using memory\"\"\"\n",
    "        print(f\"\\nü§ñ {self.name}: Processing customer query...\")\n",
    "        print(f\"üìç Department: {department}\")\n",
    "        print(f\"‚ùì Query: '{query}'\")\n",
    "        \n",
    "        # Retrieve relevant memories\n",
    "        memories = self.memory.retrieve_relevant_memories(query)\n",
    "        \n",
    "        response = self._generate_response(query, memories, department)\n",
    "        \n",
    "        # Simulate customer satisfaction\n",
    "        satisfaction = 4.0 if memories else 3.0\n",
    "        if \"price match\" in query.lower() and \"price_match\" in self.memory.procedures:\n",
    "            satisfaction = 4.5  # Following procedure improves satisfaction\n",
    "            \n",
    "        # Remember this interaction\n",
    "        self.memory.remember_customer_interaction(\n",
    "            interaction_type=\"inquiry\",\n",
    "            department=department,\n",
    "            resolution=response,\n",
    "            satisfaction=satisfaction\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _generate_response(self, query: str, memories: List, department: str) -> str:\n",
    "        \"\"\"Generate response based on memories\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Check for price match\n",
    "        if \"price match\" in query_lower or \"lower price\" in query_lower:\n",
    "            if \"price_match\" in self.memory.procedures:\n",
    "                proc = self.memory.procedures[\"price_match\"]\n",
    "                return (f\"I can help with price matching! Here's our process: \"\n",
    "                       f\"{', '.join(proc.steps[:3])}. \"\n",
    "                       f\"This typically takes {proc.average_time:.0f} minutes.\")\n",
    "        \n",
    "        # Check for product queries\n",
    "        for memory in memories:\n",
    "            if isinstance(memory, ProductKnowledge):\n",
    "                attrs = memory.attributes\n",
    "                return (f\"I found {memory.product_id}: \"\n",
    "                       f\"${attrs.get('price', 'N/A')} - {attrs.get('brand', 'Generic')} \"\n",
    "                       f\"in {memory.category}. Located in {department}.\")\n",
    "        \n",
    "        # Check for Black Friday info\n",
    "        if \"black friday\" in query_lower:\n",
    "            bf_memories = self.memory.seasonal_index.get(\"Black Friday 2023\", [])\n",
    "            if bf_memories:\n",
    "                total_sales = sum(m.revenue_impact for m in bf_memories)\n",
    "                return (f\"Black Friday was successful! We processed {len(bf_memories)} \"\n",
    "                       f\"major transactions. Our Electronics doorbusters were very popular!\")\n",
    "        \n",
    "        # Default response\n",
    "        return f\"Let me find someone in {department} to help you with that specific question.\"\n",
    "    \n",
    "    def analyze_shift_performance(self):\n",
    "        \"\"\"Analyze performance during shift\"\"\"\n",
    "        shift_duration = (datetime.now() - self.shift_start).total_seconds() / 3600\n",
    "        \n",
    "        print(f\"\\nüìä {self.name}'s Shift Analysis\")\n",
    "        print(f\"‚è∞ Shift duration: {shift_duration:.1f} hours\\n\")\n",
    "        \n",
    "        # Get department insights\n",
    "        for dept in [\"Electronics\", \"Grocery\", \"Customer Service\"]:\n",
    "            insights = self.memory.get_department_insights(dept)\n",
    "            if \"total_revenue\" in insights:\n",
    "                print(f\"üìç {dept}:\")\n",
    "                print(f\"   Revenue: ${insights['total_revenue']:,.2f}\")\n",
    "                print(f\"   Transactions: {insights['transaction_count']}\")\n",
    "                if insights['top_products']:\n",
    "                    top_product = insights['top_products'][0]\n",
    "                    print(f\"   Top item: {top_product[0]}\")\n",
    "                print()\n",
    "        \n",
    "        # Customer satisfaction\n",
    "        print(f\"üòä Customer Satisfaction: {self.memory.customer_satisfaction_avg:.2f}/5.0\")\n",
    "        \n",
    "        # Most used procedures\n",
    "        if self.memory.procedures:\n",
    "            print(f\"\\nüîß Available Procedures:\")\n",
    "            for name, proc in self.memory.procedures.items():\n",
    "                print(f\"   - {name}: {proc.success_rate:.0%} success rate\")\n",
    "\n",
    "# Create Walmart AI assistant\n",
    "assistant = WalmartAssistant(\"Sam\", \"#100\")\n",
    "print(f\"‚úÖ Walmart Assistant '{assistant.name}' is ready!\")\n",
    "print(f\"üè™ Assigned to Store {assistant.store_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Part 6: Assistant in Action\n",
    "\n",
    "Let's see our Walmart assistant handle real scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a busy retail day\n",
    "print(\"üåÖ Starting retail simulation...\\n\")\n",
    "\n",
    "# Handle customer queries throughout the day\n",
    "customer_queries = [\n",
    "    (\"9:15 AM\", \"Where can I find Samsung TVs?\", \"Electronics\"),\n",
    "    (\"10:30 AM\", \"Do you price match Amazon?\", \"Customer Service\"),\n",
    "    (\"11:45 AM\", \"Looking for gluten-free cereal\", \"Grocery\"),\n",
    "    (\"2:00 PM\", \"When is your next Black Friday?\", \"General\"),\n",
    "    (\"3:30 PM\", \"My Samsung TV from Black Friday isn't working\", \"Electronics\"),\n",
    "]\n",
    "\n",
    "for time_str, query, dept in customer_queries:\n",
    "    print(f\"\\n=== {time_str} ===\")\n",
    "    response = assistant.handle_customer_query(query, dept)\n",
    "    print(f\"üí¨ Response: {response}\")\n",
    "    time.sleep(0.5)  # Simulate time passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Hands-On Exercise: Advanced Memory Types\n",
    "\n",
    "Create specialized memory types for seasonal patterns and competitive intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create a Seasonal Pattern Memory with Advanced Analytics\n",
    "@dataclass\n",
    "class SeasonalPattern(RetailMemoryItem):\n",
    "    \"\"\"\n",
    "    Memory type that learns seasonal patterns for better inventory planning.\n",
    "    \n",
    "    This exercise teaches:\n",
    "    - Pattern recognition from historical data\n",
    "    - Weather correlation analysis\n",
    "    - Promotion effectiveness tracking\n",
    "    - Multi-year trend analysis\n",
    "    \"\"\"\n",
    "    season: str = \"\"               # spring, summer, fall, winter\n",
    "    year: int = 2024              # Which year\n",
    "    top_categories: List[str] = field(default_factory=list)\n",
    "    weather_correlation: Dict[str, float] = field(default_factory=dict)\n",
    "    promotion_effectiveness: Dict[str, float] = field(default_factory=dict)\n",
    "    total_revenue: float = 0.0\n",
    "    yoy_growth: float = 0.0       # Year-over-year growth\n",
    "    peak_shopping_days: List[str] = field(default_factory=list)\n",
    "    inventory_recommendations: Dict[str, float] = field(default_factory=dict)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.memory_type = MemoryType.SEMANTIC  # Patterns are knowledge\n",
    "        # Seasonal patterns are very important for planning\n",
    "        self.importance = 0.9\n",
    "        self.decay_rate = 0.02  # Decay very slowly - yearly relevance\n",
    "\n",
    "# Advanced implementation with pattern analysis\n",
    "def analyze_seasonal_trends(memory_manager: WalmartMemoryManager, \n",
    "                          season: str, year: int) -> SeasonalPattern:\n",
    "    \"\"\"Analyze and store seasonal patterns with business insights\"\"\"\n",
    "    # Define season months\n",
    "    season_months = {\n",
    "        \"winter\": [12, 1, 2],\n",
    "        \"spring\": [3, 4, 5],\n",
    "        \"summer\": [6, 7, 8],\n",
    "        \"fall\": [9, 10, 11]\n",
    "    }\n",
    "    \n",
    "    # Analyze episodes from that season\n",
    "    seasonal_episodes = []\n",
    "    category_revenue = defaultdict(float)\n",
    "    daily_revenue = defaultdict(float)\n",
    "    promo_performance = defaultdict(list)\n",
    "    \n",
    "    for episode in memory_manager.episodes:\n",
    "        if episode.timestamp.month in season_months.get(season, []):\n",
    "            seasonal_episodes.append(episode)\n",
    "            category_revenue[episode.department] += episode.revenue_impact\n",
    "            \n",
    "            # Track daily patterns\n",
    "            day_key = episode.timestamp.strftime(\"%A\")  # Day of week\n",
    "            daily_revenue[day_key] += episode.revenue_impact\n",
    "            \n",
    "            # Track promotion effectiveness\n",
    "            if \"event\" in episode.metadata:\n",
    "                promo_type = episode.metadata[\"event\"]\n",
    "                promo_performance[promo_type].append(episode.revenue_impact)\n",
    "    \n",
    "    # Calculate top categories\n",
    "    top_cats = sorted(category_revenue.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Find peak shopping days\n",
    "    peak_days = sorted(daily_revenue.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    # Calculate promotion effectiveness\n",
    "    promo_effectiveness = {}\n",
    "    for promo, revenues in promo_performance.items():\n",
    "        if revenues:\n",
    "            avg_revenue = sum(revenues) / len(revenues)\n",
    "            # Compare to non-promo average\n",
    "            base_avg = sum(e.revenue_impact for e in seasonal_episodes \n",
    "                          if \"event\" not in e.metadata) / max(1, len(seasonal_episodes))\n",
    "            effectiveness = (avg_revenue / base_avg - 1) * 100 if base_avg > 0 else 0\n",
    "            promo_effectiveness[promo] = effectiveness\n",
    "    \n",
    "    # Weather correlations (simulated - in reality would use weather data)\n",
    "    weather_correlation = {\n",
    "        \"temperature\": 0.7 if season == \"summer\" else -0.3,\n",
    "        \"precipitation\": -0.5 if season == \"summer\" else 0.2,\n",
    "        \"snow\": 0.8 if season == \"winter\" else -0.9\n",
    "    }\n",
    "    \n",
    "    # Inventory recommendations\n",
    "    inventory_recs = {}\n",
    "    for cat, revenue in top_cats[:5]:\n",
    "        # Recommend 20% increase for top performers\n",
    "        inventory_recs[cat] = 1.2 if revenue > 10000 else 1.0\n",
    "    \n",
    "    # Create seasonal pattern\n",
    "    pattern = SeasonalPattern(\n",
    "        content=f\"Seasonal pattern for {season} {year}\",\n",
    "        timestamp=datetime.now(),\n",
    "        importance=0.9,\n",
    "        season=season,\n",
    "        year=year,\n",
    "        top_categories=[cat for cat, _ in top_cats[:5]],\n",
    "        total_revenue=sum(category_revenue.values()),\n",
    "        weather_correlation=weather_correlation,\n",
    "        promotion_effectiveness=promo_effectiveness,\n",
    "        peak_shopping_days=[day for day, _ in peak_days],\n",
    "        inventory_recommendations=inventory_recs,\n",
    "        yoy_growth=random.uniform(-5, 15)  # Simulated\n",
    "    )\n",
    "    \n",
    "    return pattern\n",
    "\n",
    "# TODO: Student Challenge - Extend this to:\n",
    "# 1. Compare patterns across multiple years\n",
    "# 2. Predict next season's trends\n",
    "# 3. Suggest optimal promotion timing\n",
    "# 4. Identify weather-sensitive products\n",
    "\n",
    "# Test the enhanced implementation\n",
    "print(\"üçÇ Analyzing Fall 2023 patterns with advanced metrics...\")\n",
    "fall_pattern = analyze_seasonal_trends(assistant.memory, \"fall\", 2023)\n",
    "print(f\"\\nTop categories: {', '.join(fall_pattern.top_categories[:3])}\")\n",
    "print(f\"Total revenue: ${fall_pattern.total_revenue:,.2f}\")\n",
    "print(f\"Peak shopping days: {', '.join(fall_pattern.peak_shopping_days)}\")\n",
    "\n",
    "if fall_pattern.promotion_effectiveness:\n",
    "    best_promo = max(fall_pattern.promotion_effectiveness.items(), key=lambda x: x[1])\n",
    "    print(f\"Most effective promotion: {best_promo[0]} (+{best_promo[1]:.1f}% revenue)\")\n",
    "\n",
    "print(\"\\nüìà Inventory Recommendations:\")\n",
    "for cat, multiplier in fall_pattern.inventory_recommendations.items():\n",
    "    if multiplier > 1.0:\n",
    "        print(f\"  - {cat}: Increase by {(multiplier-1)*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Summary and Key Takeaways\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "1. **Retail-Specific Memory Architecture**:\n",
    "   - Working Memory: Current store state and active customers\n",
    "   - Episodic Memory: Sales transactions and customer interactions\n",
    "   - Semantic Memory: Product knowledge and relationships\n",
    "   - Procedural Memory: Operational workflows with ROI tracking\n",
    "\n",
    "2. **LLM Integration**:\n",
    "   - Ollama/Qwen2.5 for intelligent memory retrieval\n",
    "   - Semantic similarity scoring beyond keyword matching\n",
    "   - Query intent extraction for better relevance\n",
    "   - Graceful fallback when LLM unavailable\n",
    "\n",
    "3. **Advanced Memory Features**:\n",
    "   - Ebbinghaus forgetting curve implementation\n",
    "   - Automatic consolidation based on importance\n",
    "   - Multi-factor relevance scoring\n",
    "   - Recency and frequency effects\n",
    "\n",
    "4. **Business Intelligence**:\n",
    "   - Revenue impact tracking per memory\n",
    "   - Customer satisfaction monitoring\n",
    "   - Department-level insights\n",
    "   - Seasonal pattern recognition\n",
    "\n",
    "5. **Learning from Retail Operations**:\n",
    "   - Product relationship discovery (frequently bought together)\n",
    "   - Procedure effectiveness measurement\n",
    "   - Customer service improvement tracking\n",
    "   - Black Friday and seasonal preparation\n",
    "\n",
    "### üöÄ Real-World Applications:\n",
    "\n",
    "This memory system could power:\n",
    "- **Smart Inventory Management**: Predictive restocking\n",
    "- **Customer Service Bots**: Context-aware assistance\n",
    "- **Revenue Optimization**: Data-driven pricing and promotions\n",
    "- **Operational Excellence**: Learning from successful procedures\n",
    "\n",
    "### üí° Challenge Exercise:\n",
    "\n",
    "Implement a **Competitive Intelligence Memory** that:\n",
    "1. Tracks competitor pricing and promotions\n",
    "2. Learns which price matches drive sales\n",
    "3. Identifies market trends and opportunities\n",
    "4. Suggests competitive strategies\n",
    "\n",
    "### üìà Business Impact:\n",
    "\n",
    "With proper implementation, this system could:\n",
    "- Increase customer satisfaction by 15%\n",
    "- Reduce inventory waste by 20%\n",
    "- Improve checkout efficiency by 25%\n",
    "- Boost seasonal revenue by 10%\n",
    "\n",
    "Ready for Module 3? We'll connect these agents to real databases and APIs! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}