{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🚀 Environment Setup\n\n### Prerequisites\n\nBefore starting this module, you need Qwen2.5 7B Instruct model set up locally via Ollama.\n\n**Quick Setup:**\n```bash\n# Run the automated setup script\nbash setup_ollama.sh\n```\n\nThis script will:\n- ✅ Install Ollama (if not already installed)\n- ✅ Download Qwen2.5 7B Instruct (4.7GB) \n- ✅ Test function calling capabilities\n- ✅ Create configuration files\n\n### Why Qwen2.5 7B for Agents?\n\nWe chose Qwen2.5 7B Instruct as our premier model for agent development because:\n\n- **🎯 Native Function Calling**: Built-in tool calling with 92% accuracy\n- **⚡ Optimal Performance**: 15-20 tokens/sec on M1 Pro, 1-2s response time\n- **🧠 Smart Reasoning**: Handles 5-7 step logical chains effectively  \n- **💾 Memory Efficient**: Perfect for 16GB systems with context headroom\n- **🔄 Multi-turn**: Excellent conversation and context retention\n\n### Why Local LLMs?\n\n- **🔒 Privacy**: Your agent development stays on your machine\n- **⚙️ Control**: You own the entire inference stack\n- **📚 Learning**: See exactly how LLM integration works\n- **💰 Cost**: No API fees for experimentation!\"",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Configuration\nMODEL_NAME = \"qwen2.5:7b-instruct-q4_K_M\"  # Qwen2.5 7B Instruct quantized model\nOLLAMA_BASE_URL = \"http://localhost:11434\"\n\n# Test the connection\nimport requests\nimport json\n\ntry:\n    # Test basic connectivity\n    response = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\", timeout=5)\n    if response.status_code == 200:\n        print(\"✅ Ollama server is running\")\n        \n        # Test model availability\n        models = response.json().get('models', [])\n        model_names = [model['name'] for model in models]\n        \n        if MODEL_NAME in model_names:\n            print(f\"✅ {MODEL_NAME} is available\")\n        else:\n            print(f\"❌ {MODEL_NAME} not found. Available models: {model_names}\")\n            print(\"Run the setup script to download the model.\")\n    else:\n        print(f\"❌ Ollama server responded with status {response.status_code}\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"❌ Cannot connect to Ollama: {e}\")\n    print(\"Make sure Ollama is installed and running (ollama serve)\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "## What We'll Build Today\n\nIn this notebook, we'll create a complete AI agent from scratch using **first principles**. No frameworks, no black boxes - just clean, understandable code that demonstrates core agent concepts.\n\n### Learning Objectives\n\nBy the end of this module, you'll understand:\n\n1. **Agent Architecture**: The four core components every agent needs\n2. **ReAct Pattern**: How agents think, act, and learn from observations  \n3. **State Management**: Tracking agent progress and context\n4. **Tool Integration**: Building and using external capabilities\n5. **Function Calling**: Structured communication with language models\n\n### Our Agent's Capabilities\n\nWe'll build an agent that can:\n- 🧮 **Calculate**: Perform mathematical operations\n- 🌐 **Search**: Find information on the web\n- 💾 **Remember**: Store and retrieve information\n- 🎯 **Plan**: Break down complex tasks into steps\n- 🔄 **Adapt**: Learn from experience and improve over time\n\n### Why First Principles?\n\nBuilding from scratch helps you:\n- **Understand deeply** how each component works\n- **Debug effectively** when things go wrong\n- **Customize freely** for your specific needs\n- **Scale confidently** with full system knowledge\n\nLet's start building! 🚀"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Part 1: What Makes a System \"Agentic\"?\n",
    "\n",
    "### The Spectrum of AI Systems\n",
    "\n",
    "Not all AI systems are agents. Let's understand the spectrum:\n",
    "\n",
    "```\n",
    "REACTIVE                                                    AGENTIC\n",
    "    │                                                          │\n",
    "    ├─────────────┬──────────────┬──────────────┬────────────┤\n",
    "    │             │              │              │            │\n",
    " Chatbot      Assistant      Copilot       Agent      Autonomous\n",
    "                                                          System\n",
    "    \n",
    "Examples:\n",
    "- Chatbot: Responds to queries\n",
    "- Assistant: Helps with tasks\n",
    "- Copilot: Suggests next steps\n",
    "- Agent: Acts autonomously toward goals\n",
    "- Autonomous System: Self-directed with multiple agents\n",
    "```\n",
    "\n",
    "### Key Properties of Agents\n",
    "\n",
    "1. **Autonomy**: Can make decisions without human intervention\n",
    "2. **Goal-Oriented**: Works toward specific objectives\n",
    "3. **Persistence**: Maintains state across interactions\n",
    "4. **Reactivity**: Responds to environmental changes\n",
    "5. **Proactivity**: Takes initiative to achieve goals\n",
    "\n",
    "### The Agent Control Loop\n",
    "\n",
    "Every agent, from simple to complex, follows this fundamental loop:\n",
    "\n",
    "```\n",
    "    ┌─────────────────────────────────────┐\n",
    "    │                                     │\n",
    "    │  SENSE → THINK → ACT → LEARN       │\n",
    "    │    ↑                      │        │\n",
    "    │    └──────────────────────┘        │\n",
    "    │                                     │\n",
    "    └─────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "Let's build this from first principles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Part 2: Core Agent Architecture\n",
    "\n",
    "### Building Blocks\n",
    "\n",
    "We'll construct our agent using these fundamental components:\n",
    "\n",
    "1. **State** - The agent's memory and context\n",
    "2. **Brain** - LLM integration for reasoning\n",
    "3. **Tools** - Capabilities beyond text generation\n",
    "4. **Controller** - Orchestrates the agent loop\n",
    "\n",
    "### Design Philosophy\n",
    "\n",
    "- **Explicit over implicit**: Every decision is visible\n",
    "- **Simple over complex**: Start minimal, add only what's needed\n",
    "- **Educational over efficient**: Clarity beats performance\n",
    "- **Debuggable over clever**: You should understand every line"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# First, let's define agent states - this helps us track what the agent is doing\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Any, Optional, Tuple\nimport time\n\nclass AgentState(Enum):\n    \"\"\"Possible states for our agent - like a state machine\"\"\"\n    IDLE = \"idle\"              # Waiting for a task\n    THINKING = \"thinking\"      # Processing with LLM\n    ACTING = \"acting\"          # Executing a tool\n    OBSERVING = \"observing\"    # Processing tool results\n    COMPLETED = \"completed\"    # Task finished\n    ERROR = \"error\"           # Something went wrong\n\n# Define what an action looks like\n@dataclass\nclass AgentAction:\n    \"\"\"\n    Represents a single action the agent wants to take.\n    This is the bridge between thinking and doing.\n    \"\"\"\n    tool_name: str          # Which tool to use\n    tool_input: str         # What to pass to the tool\n    reasoning: str          # Why this action was chosen\n    confidence: float = 0.0 # How confident (0-1)\n\n# Configuration for our agent\n@dataclass\nclass AgentConfig:\n    \"\"\"\n    Configuration parameters for agent behavior.\n    These knobs let us tune how the agent operates.\n    \"\"\"\n    name: str = \"Agent\"\n    model: str = \"qwen2.5:7b-instruct-q4_K_M\"  # Qwen2.5 7B Instruct model\n    max_iterations: int = 5          # Prevent infinite loops\n    verbose: bool = True             # Show reasoning process\n    temperature: float = 0.7         # LLM creativity (0=deterministic, 1=creative)\n    timeout_seconds: int = 30        # Max time per action\n    \n# The context/memory structure\n@dataclass \nclass AgentContext:\n    \"\"\"\n    The agent's working memory - everything it needs to remember.\n    This is crucial for maintaining context across actions.\n    \"\"\"\n    goal: str                           # What we're trying to achieve\n    conversation_history: List[Dict] = field(default_factory=list)  # Past interactions\n    action_history: List[AgentAction] = field(default_factory=list) # What we've done\n    observations: List[str] = field(default_factory=list)           # What we've learned\n    current_plan: List[str] = field(default_factory=list)          # Steps to take\n    iteration: int = 0                  # How many cycles we've done\n    start_time: float = field(default_factory=time.time)           # When we started\n    \n    def add_to_history(self, role: str, content: str):\n        \"\"\"Add an interaction to conversation history\"\"\"\n        self.conversation_history.append({\n            \"role\": role,\n            \"content\": content,\n            \"timestamp\": time.time()\n        })\n    \n    def get_summary(self) -> str:\n        \"\"\"Get a summary of current context for the LLM\"\"\"\n        summary = f\"Goal: {self.goal}\\n\"\n        summary += f\"Iteration: {self.iteration}\\n\"\n        \n        if self.action_history:\n            summary += \"\\nPrevious actions:\\n\"\n            for action in self.action_history[-3:]:  # Last 3 actions\n                summary += f\"- {action.tool_name}: {action.reasoning}\\n\"\n        \n        if self.observations:\n            summary += \"\\nKey observations:\\n\"\n            for obs in self.observations[-3:]:  # Last 3 observations\n                summary += f\"- {obs}\\n\"\n                \n        return summary\n\nprint(\"✅ Core data structures defined!\")\nprint(\"\\n📊 Agent State Machine:\")\nfor state in AgentState:\n    print(f\"  - {state.value}: {state.name}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Part 3: LLM Integration with Ollama\n",
    "\n",
    "### Understanding LLM's Role\n",
    "\n",
    "The LLM serves as the agent's \"brain\" - it:\n",
    "- **Reasons** about the current situation\n",
    "- **Decides** what action to take next\n",
    "- **Interprets** results from tools\n",
    "- **Plans** multi-step solutions\n",
    "\n",
    "### Prompt Engineering for Agents\n",
    "\n",
    "Agent prompts are different from chatbot prompts. They need:\n",
    "1. **Clear role definition**\n",
    "2. **Structured output format**\n",
    "3. **Available tools description**\n",
    "4. **Reasoning instructions**\n",
    "\n",
    "Let's build a robust LLM integration:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "class OllamaLLM:\n    \"\"\"\n    Our interface to Ollama - handles all LLM communication.\n    This is our agent's 'brain' that does the reasoning.\n    \"\"\"\n    \n    def __init__(self, model: str = \"qwen2.5:7b-instruct-q4_K_M\", temperature: float = 0.7):\n        self.model = model\n        self.temperature = temperature\n        self.base_url = \"http://localhost:11434\"\n        \n    def generate(self, prompt: str, system: str = \"\") -> str:\n        \"\"\"\n        Generate a response from the LLM.\n        \n        Args:\n            prompt: The user prompt\n            system: System prompt to set behavior\n            \n        Returns:\n            The LLM's response text\n        \"\"\"\n        # Combine system and user prompts\n        full_prompt = f\"{system}\\n\\nUser: {prompt}\\n\\nAssistant:\" if system else prompt\n        \n        try:\n            response = requests.post(\n                f\"{self.base_url}/api/generate\",\n                json={\n                    \"model\": self.model,\n                    \"prompt\": full_prompt,\n                    \"temperature\": self.temperature,\n                    \"stream\": False\n                },\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                return response.json().get('response', '')\n            else:\n                raise Exception(f\"Ollama error: {response.status_code}\")\n                \n        except requests.exceptions.Timeout:\n            return \"Error: LLM request timed out. Try a shorter prompt.\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n    \n    def generate_structured(self, prompt: str, system: str = \"\") -> Dict[str, Any]:\n        \"\"\"\n        Generate a structured response (JSON) from the LLM.\n        This is crucial for agent actions that need parsing.\n        \"\"\"\n        # Add JSON instruction to prompt\n        json_prompt = f\"{prompt}\\n\\nRespond ONLY with valid JSON, no other text.\"\n        \n        response = self.generate(json_prompt, system)\n        \n        # Try to parse JSON from response\n        try:\n            # Clean up response - LLMs sometimes add extra text\n            json_str = response.strip()\n            if \"```json\" in json_str:\n                json_str = json_str.split(\"```json\")[1].split(\"```\")[0]\n            elif \"```\" in json_str:\n                json_str = json_str.split(\"```\")[1].split(\"```\")[0]\n            \n            return json.loads(json_str)\n        except:\n            # Fallback for parsing errors\n            return {\n                \"error\": \"Failed to parse LLM response as JSON\",\n                \"raw_response\": response\n            }\n\n# Test the LLM integration\nllm = OllamaLLM(model=MODEL_NAME)\n\nprint(\"🧪 Testing LLM integration...\")\ntest_response = llm.generate(\n    \"Hello! Please respond with: 'LLM integration successful'\",\n    system=\"You are a helpful assistant.\"\n)\nprint(f\"\\n📝 LLM Response: {test_response[:100]}...\")\n\n# Test structured output\nprint(\"\\n🧪 Testing structured output...\")\nstruct_response = llm.generate_structured(\n    'Create a JSON object with fields: \"status\" (set to \"ok\") and \"message\" (set to \"test complete\")',\n    system=\"You are a JSON generator. Only output valid JSON.\"\n)\nprint(f\"📊 Structured Response: {struct_response}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Part 4: Building Tools\n",
    "\n",
    "### What Are Tools?\n",
    "\n",
    "Tools extend the agent's capabilities beyond text generation. They're the agent's way of:\n",
    "- **Accessing** external information\n",
    "- **Performing** calculations\n",
    "- **Interacting** with systems\n",
    "- **Storing** and retrieving data\n",
    "\n",
    "### Tool Design Principles\n",
    "\n",
    "1. **Single Responsibility**: Each tool does one thing well\n",
    "2. **Clear Interface**: Simple input → output\n",
    "3. **Error Handling**: Always return something useful\n",
    "4. **Self-Describing**: The tool explains what it does\n",
    "\n",
    "### Tool Execution Safety\n",
    "\n",
    "Since agents execute tools autonomously, we need:\n",
    "- Input validation\n",
    "- Error boundaries  \n",
    "- Timeout protection\n",
    "- Result sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base tool interface\n",
    "class Tool:\n",
    "    \"\"\"\n",
    "    Base class for all tools. Every tool must:\n",
    "    1. Have a name and description\n",
    "    2. Implement the execute method\n",
    "    3. Handle errors gracefully\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, description: str):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        \n",
    "    def execute(self, input_str: str) -> str:\n",
    "        \"\"\"Execute the tool with given input\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement execute\")\n",
    "        \n",
    "    def validate_input(self, input_str: str) -> Tuple[bool, str]:\n",
    "        \"\"\"Validate input before execution\"\"\"\n",
    "        if not input_str or not isinstance(input_str, str):\n",
    "            return False, \"Input must be a non-empty string\"\n",
    "        return True, \"Valid\"\n",
    "\n",
    "# Concrete tool implementations\n",
    "class SearchTool(Tool):\n",
    "    \"\"\"\n",
    "    Simulated web search tool.\n",
    "    In production, this would call a real search API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"search\",\n",
    "            description=\"Search for information on any topic. Input: search query\"\n",
    "        )\n",
    "        # Simulated knowledge base\n",
    "        self.knowledge_base = {\n",
    "            \"ai agents\": \"AI agents are autonomous systems that perceive, reason, and act to achieve goals.\",\n",
    "            \"react pattern\": \"ReAct combines reasoning and acting in a loop for better agent behavior.\",\n",
    "            \"llm\": \"Large Language Models are neural networks trained on vast text data.\",\n",
    "            \"python\": \"Python is a high-level programming language known for simplicity.\",\n",
    "            \"climate\": \"Climate change refers to long-term shifts in global temperatures.\"\n",
    "        }\n",
    "    \n",
    "    def execute(self, query: str) -> str:\n",
    "        valid, msg = self.validate_input(query)\n",
    "        if not valid:\n",
    "            return f\"Search error: {msg}\"\n",
    "            \n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Find relevant results\n",
    "        results = []\n",
    "        for key, value in self.knowledge_base.items():\n",
    "            if any(word in query_lower for word in key.split()):\n",
    "                results.append(value)\n",
    "        \n",
    "        if results:\n",
    "            return f\"Search results for '{query}': \" + \" \".join(results[:2])\n",
    "        else:\n",
    "            return f\"No specific results found for '{query}'. Try different keywords.\"\n",
    "\n",
    "class CalculatorTool(Tool):\n",
    "    \"\"\"\n",
    "    Safe calculator for mathematical expressions.\n",
    "    Uses eval() with strict input validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"calculator\", \n",
    "            description=\"Perform mathematical calculations. Input: mathematical expression\"\n",
    "        )\n",
    "        self.allowed_chars = set('0123456789+-*/()., ')\n",
    "        self.allowed_names = {'abs', 'round', 'min', 'max'}\n",
    "    \n",
    "    def execute(self, expression: str) -> str:\n",
    "        valid, msg = self.validate_input(expression)\n",
    "        if not valid:\n",
    "            return f\"Calculator error: {msg}\"\n",
    "        \n",
    "        # Security: validate expression characters\n",
    "        if not all(c in self.allowed_chars for c in expression):\n",
    "            return \"Error: Invalid characters in expression. Use only numbers and +-*/().\"\n",
    "        \n",
    "        try:\n",
    "            # Create safe namespace\n",
    "            safe_dict = {name: getattr(__builtins__, name) for name in self.allowed_names}\n",
    "            result = eval(expression, {\"__builtins__\": {}}, safe_dict)\n",
    "            return f\"Result: {result}\"\n",
    "        except ZeroDivisionError:\n",
    "            return \"Error: Division by zero\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: Invalid expression - {str(e)}\"\n",
    "\n",
    "class MemoryTool(Tool):\n",
    "    \"\"\"\n",
    "    Simple key-value memory storage.\n",
    "    Allows agent to store and retrieve information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"memory\",\n",
    "            description=\"Store or retrieve information. Input: 'store key=value' or 'get key'\"\n",
    "        )\n",
    "        self.storage = {}\n",
    "    \n",
    "    def execute(self, command: str) -> str:\n",
    "        valid, msg = self.validate_input(command)\n",
    "        if not valid:\n",
    "            return f\"Memory error: {msg}\"\n",
    "            \n",
    "        parts = command.strip().split(maxsplit=1)\n",
    "        if len(parts) < 2:\n",
    "            return \"Error: Use 'store key=value' or 'get key'\"\n",
    "            \n",
    "        action, data = parts[0].lower(), parts[1]\n",
    "        \n",
    "        if action == \"store\":\n",
    "            if '=' not in data:\n",
    "                return \"Error: Store format is 'store key=value'\"\n",
    "            key, value = data.split('=', 1)\n",
    "            self.storage[key.strip()] = value.strip()\n",
    "            return f\"Stored: {key.strip()} = {value.strip()}\"\n",
    "            \n",
    "        elif action == \"get\":\n",
    "            key = data.strip()\n",
    "            if key in self.storage:\n",
    "                return f\"Retrieved: {key} = {self.storage[key]}\"\n",
    "            else:\n",
    "                return f\"Not found: {key}\"\n",
    "                \n",
    "        else:\n",
    "            return \"Error: Unknown action. Use 'store' or 'get'\"\n",
    "\n",
    "# Create and test tools\n",
    "print(\"🔧 Creating tools...\")\n",
    "tools = {\n",
    "    \"search\": SearchTool(),\n",
    "    \"calculator\": CalculatorTool(), \n",
    "    \"memory\": MemoryTool()\n",
    "}\n",
    "\n",
    "# Test each tool\n",
    "print(\"\\n🧪 Testing tools:\")\n",
    "print(\"\\n1. Search Tool:\")\n",
    "print(f\"   Result: {tools['search'].execute('AI agents')}\")\n",
    "\n",
    "print(\"\\n2. Calculator Tool:\")\n",
    "print(f\"   Result: {tools['calculator'].execute('(10 + 5) * 2')}\")\n",
    "print(f\"   Error handling: {tools['calculator'].execute('10 / 0')}\")\n",
    "\n",
    "print(\"\\n3. Memory Tool:\")\n",
    "print(f\"   Store: {tools['memory'].execute('store name=ResearchBot')}\")\n",
    "print(f\"   Retrieve: {tools['memory'].execute('get name')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Part 5: The ReAct Pattern\n",
    "\n",
    "### What is ReAct?\n",
    "\n",
    "ReAct (Reasoning + Acting) is a cognitive architecture that interleaves:\n",
    "- **Reasoning**: Thinking about what to do\n",
    "- **Acting**: Actually doing it\n",
    "- **Observing**: Learning from results\n",
    "\n",
    "### Why ReAct Works\n",
    "\n",
    "Traditional approaches separate thinking and acting. ReAct combines them:\n",
    "\n",
    "```\n",
    "Traditional:             ReAct:\n",
    "Think → Think → Act      Think → Act → Observe → Think → Act → Observe\n",
    "        ↓                                                         ↓\n",
    "   Often wrong                                        Self-correcting\n",
    "```\n",
    "\n",
    "### ReAct Prompt Structure\n",
    "\n",
    "The key to ReAct is structuring prompts to encourage step-by-step reasoning:\n",
    "\n",
    "1. **Thought**: What should I do next and why?\n",
    "2. **Action**: Which tool and what input?\n",
    "3. **Observation**: What did I learn?\n",
    "4. **Repeat**: Until goal achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "    \"\"\"\n",
    "    Our main agent class implementing the ReAct pattern.\n",
    "    This is where everything comes together!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: AgentConfig):\n",
    "        self.config = config\n",
    "        self.llm = OllamaLLM(model=config.model, temperature=config.temperature)\n",
    "        self.tools = {}\n",
    "        self.state = AgentState.IDLE\n",
    "        self.context = None\n",
    "        \n",
    "    def add_tool(self, tool: Tool):\n",
    "        \"\"\"Register a tool with the agent\"\"\"\n",
    "        self.tools[tool.name] = tool\n",
    "        if self.config.verbose:\n",
    "            print(f\"✅ Added tool: {tool.name}\")\n",
    "    \n",
    "    def _update_state(self, new_state: AgentState):\n",
    "        \"\"\"Update agent state with logging\"\"\"\n",
    "        if self.config.verbose:\n",
    "            print(f\"\\n🔄 State: {self.state.value} → {new_state.value}\")\n",
    "        self.state = new_state\n",
    "    \n",
    "    def _create_system_prompt(self) -> str:\n",
    "        \"\"\"Create the system prompt that defines agent behavior\"\"\"\n",
    "        tool_descriptions = \"\\n\".join([\n",
    "            f\"- {name}: {tool.description}\"\n",
    "            for name, tool in self.tools.items()\n",
    "        ])\n",
    "        \n",
    "        return f\"\"\"You are {self.config.name}, an autonomous AI agent using the ReAct pattern.\n",
    "\n",
    "You have access to these tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "For each step, you must:\n",
    "1. THOUGHT: Analyze the current situation and plan your next action\n",
    "2. ACTION: Choose a tool and provide input\n",
    "3. Wait for OBSERVATION\n",
    "4. Repeat until the goal is achieved\n",
    "\n",
    "IMPORTANT: \n",
    "- Always start with a THOUGHT\n",
    "- Use tools to gather information or perform actions\n",
    "- Be concise and focused\n",
    "- Learn from observations to improve your approach\n",
    "\n",
    "Format your response as:\n",
    "THOUGHT: [your reasoning]\n",
    "ACTION: [tool_name] [input]\n",
    "\"\"\"\n",
    "    \n",
    "    def _parse_llm_response(self, response: str) -> Optional[AgentAction]:\n",
    "        \"\"\"Parse LLM response to extract action\"\"\"\n",
    "        lines = response.strip().split('\\n')\n",
    "        \n",
    "        thought = \"\"\n",
    "        action_line = \"\"\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"THOUGHT:\"):\n",
    "                thought = line.replace(\"THOUGHT:\", \"\").strip()\n",
    "            elif line.strip().startswith(\"ACTION:\"):\n",
    "                action_line = line.replace(\"ACTION:\", \"\").strip()\n",
    "        \n",
    "        if not action_line:\n",
    "            return None\n",
    "            \n",
    "        # Parse action line\n",
    "        parts = action_line.split(maxsplit=1)\n",
    "        if len(parts) < 2:\n",
    "            return None\n",
    "            \n",
    "        tool_name = parts[0]\n",
    "        tool_input = parts[1] if len(parts) > 1 else \"\"\n",
    "        \n",
    "        return AgentAction(\n",
    "            tool_name=tool_name,\n",
    "            tool_input=tool_input,\n",
    "            reasoning=thought\n",
    "        )\n",
    "    \n",
    "    def _execute_action(self, action: AgentAction) -> str:\n",
    "        \"\"\"Execute an action using the appropriate tool\"\"\"\n",
    "        if action.tool_name not in self.tools:\n",
    "            return f\"Error: Unknown tool '{action.tool_name}'\"\n",
    "            \n",
    "        tool = self.tools[action.tool_name]\n",
    "        \n",
    "        try:\n",
    "            result = tool.execute(action.tool_input)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error executing {action.tool_name}: {str(e)}\"\n",
    "    \n",
    "    def think(self, context: AgentContext) -> Optional[AgentAction]:\n",
    "        \"\"\"Generate next action using LLM reasoning\"\"\"\n",
    "        self._update_state(AgentState.THINKING)\n",
    "        \n",
    "        # Build prompt with context\n",
    "        prompt = f\"\"\"Current context:\n",
    "{context.get_summary()}\n",
    "\n",
    "What should I do next to achieve the goal?\n",
    "\"\"\"\n",
    "        \n",
    "        # Get LLM response\n",
    "        response = self.llm.generate(prompt, self._create_system_prompt())\n",
    "        \n",
    "        if self.config.verbose:\n",
    "            print(f\"\\n💭 LLM Response:\\n{response}\")\n",
    "        \n",
    "        # Parse action from response\n",
    "        action = self._parse_llm_response(response)\n",
    "        \n",
    "        if action:\n",
    "            context.add_to_history(\"assistant\", response)\n",
    "            context.action_history.append(action)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def act(self, action: AgentAction) -> str:\n",
    "        \"\"\"Execute the chosen action\"\"\"\n",
    "        self._update_state(AgentState.ACTING)\n",
    "        \n",
    "        if self.config.verbose:\n",
    "            print(f\"\\n🔧 Executing: {action.tool_name} with input: {action.tool_input}\")\n",
    "        \n",
    "        result = self._execute_action(action)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def observe(self, observation: str, context: AgentContext):\n",
    "        \"\"\"Process the observation from action\"\"\"\n",
    "        self._update_state(AgentState.OBSERVING)\n",
    "        \n",
    "        if self.config.verbose:\n",
    "            print(f\"\\n👁️ Observation: {observation}\")\n",
    "        \n",
    "        context.observations.append(observation)\n",
    "        context.add_to_history(\"observation\", observation)\n",
    "    \n",
    "    def run(self, goal: str) -> str:\n",
    "        \"\"\"Run the agent to achieve a goal\"\"\"\n",
    "        print(f\"\\n🎯 Starting agent with goal: {goal}\")\n",
    "        \n",
    "        # Initialize context\n",
    "        context = AgentContext(goal=goal)\n",
    "        self.context = context\n",
    "        \n",
    "        # Main agent loop\n",
    "        while context.iteration < self.config.max_iterations:\n",
    "            context.iteration += 1\n",
    "            \n",
    "            if self.config.verbose:\n",
    "                print(f\"\\n{'='*50}\")\n",
    "                print(f\"Iteration {context.iteration}/{self.config.max_iterations}\")\n",
    "                print(f\"{'='*50}\")\n",
    "            \n",
    "            # Think\n",
    "            action = self.think(context)\n",
    "            if not action:\n",
    "                print(\"\\n❌ Could not determine next action\")\n",
    "                break\n",
    "            \n",
    "            # Act\n",
    "            result = self.act(action)\n",
    "            \n",
    "            # Observe\n",
    "            self.observe(result, context)\n",
    "            \n",
    "            # Check if goal achieved (simple heuristic)\n",
    "            if \"error\" not in result.lower() and context.iteration > 1:\n",
    "                # Ask LLM if goal is achieved\n",
    "                check_prompt = f\"\"\"Based on the context and observations, has the goal been achieved?\n",
    "Goal: {goal}\n",
    "Latest observation: {result}\n",
    "\n",
    "Answer with just YES or NO.\"\"\"\n",
    "                \n",
    "                check_response = self.llm.generate(check_prompt).strip().upper()\n",
    "                if \"YES\" in check_response:\n",
    "                    self._update_state(AgentState.COMPLETED)\n",
    "                    print(\"\\n✅ Goal achieved!\")\n",
    "                    break\n",
    "        \n",
    "        # Prepare final summary\n",
    "        if context.iteration >= self.config.max_iterations:\n",
    "            print(\"\\n⏰ Reached maximum iterations\")\n",
    "        \n",
    "        return self._generate_summary(context)\n",
    "    \n",
    "    def _generate_summary(self, context: AgentContext) -> str:\n",
    "        \"\"\"Generate a summary of the agent's work\"\"\"\n",
    "        summary = f\"\\n📊 Agent Summary:\\n\"\n",
    "        summary += f\"Goal: {context.goal}\\n\"\n",
    "        summary += f\"Iterations: {context.iteration}\\n\"\n",
    "        summary += f\"Actions taken: {len(context.action_history)}\\n\"\n",
    "        summary += f\"Final state: {self.state.value}\\n\"\n",
    "        \n",
    "        if context.observations:\n",
    "            summary += f\"\\nKey findings:\\n\"\n",
    "            for obs in context.observations[-3:]:\n",
    "                summary += f\"- {obs}\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Create and configure agent\n",
    "print(\"🤖 Creating ReAct agent...\")\n",
    "agent_config = AgentConfig(\n",
    "    name=\"ResearchBot\",\n",
    "    model=MODEL_NAME,\n",
    "    max_iterations=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent = ReActAgent(agent_config)\n",
    "\n",
    "# Add tools\n",
    "for tool in tools.values():\n",
    "    agent.add_tool(tool)\n",
    "\n",
    "print(\"\\n✅ Agent ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Part 6: Agent in Action\n",
    "\n",
    "### Running Your First Agent Task\n",
    "\n",
    "Let's see our agent solve a real problem. Watch how it:\n",
    "1. Breaks down the goal\n",
    "2. Chooses appropriate tools\n",
    "3. Learns from observations\n",
    "4. Achieves the objective\n",
    "\n",
    "### Understanding the Output\n",
    "\n",
    "Pay attention to:\n",
    "- **State transitions**: How the agent moves through states\n",
    "- **Reasoning process**: Why it chooses certain actions\n",
    "- **Error recovery**: How it handles unexpected results\n",
    "- **Goal achievement**: How it knows when to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: Simple calculation task\n",
    "print(\"📝 Demo 1: Simple Calculation\")\n",
    "print(\"Task: Calculate the area of a rectangle with width 15 and height 23\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "result = agent.run(\"Calculate the area of a rectangle with width 15 and height 23\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: Multi-step research task\n",
    "print(\"\\n📝 Demo 2: Research Task\")\n",
    "print(\"Task: Research AI agents and store key findings\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "result = agent.run(\"Research what AI agents are and store the key findings in memory\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Hands-On Exercises\n",
    "\n",
    "### Exercise 1: Build Your Own Tool\n",
    "\n",
    "Create a custom tool that the agent can use. Some ideas:\n",
    "- Weather tool (return mock weather data)\n",
    "- Time tool (return current time/date)\n",
    "- File tool (read/write simple files)\n",
    "- Translation tool (simple word mappings)\n",
    "\n",
    "### Exercise 2: Improve the Agent\n",
    "\n",
    "Enhance the agent with:\n",
    "- Better goal detection\n",
    "- Smarter error recovery\n",
    "- Tool chaining optimization\n",
    "- Context summarization\n",
    "\n",
    "### Exercise 3: Debug Challenge\n",
    "\n",
    "Fix the intentionally broken agent below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Build Your Own Tool\n",
    "print(\"🎓 EXERCISE 1: Build a Weather Tool\")\n",
    "print(\"Complete the WeatherTool implementation below:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "class WeatherTool(Tool):\n",
    "    \"\"\"\n",
    "    TODO: Implement a weather tool that:\n",
    "    1. Takes a city name as input\n",
    "    2. Returns mock weather data\n",
    "    3. Handles invalid cities gracefully\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"weather\",\n",
    "            description=\"Get weather for a city. Input: city name\"\n",
    "        )\n",
    "        # TODO: Add mock weather data\n",
    "        self.weather_data = {\n",
    "            # Add your cities and weather here\n",
    "        }\n",
    "    \n",
    "    def execute(self, city: str) -> str:\n",
    "        # TODO: Implement weather lookup\n",
    "        # 1. Validate input\n",
    "        # 2. Look up weather\n",
    "        # 3. Return formatted result\n",
    "        return \"TODO: Implement this method\"\n",
    "\n",
    "# Test your implementation\n",
    "# weather_tool = WeatherTool()\n",
    "# print(weather_tool.execute(\"London\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Module Summary & Next Steps\n",
    "\n",
    "### 🎯 What You've Learned\n",
    "\n",
    "**Core Concepts:**\n",
    "- ✅ What makes a system \"agentic\" vs reactive\n",
    "- ✅ First principles agent architecture\n",
    "- ✅ Local LLM integration with Ollama\n",
    "- ✅ The ReAct cognitive pattern\n",
    "- ✅ Tool design and integration\n",
    "- ✅ State management and control flow\n",
    "- ✅ Error handling and recovery\n",
    "\n",
    "**Practical Skills:**\n",
    "- ✅ Building agents from scratch (no frameworks!)\n",
    "- ✅ Debugging agent behavior\n",
    "- ✅ Creating custom tools\n",
    "- ✅ Prompt engineering for agents\n",
    "- ✅ Managing agent execution loops\n",
    "\n",
    "### 🔑 Key Takeaways\n",
    "\n",
    "1. **Agents = Autonomy + Goals + Tools + State**\n",
    "2. **ReAct Pattern** enables self-correcting behavior\n",
    "3. **Tools** extend agent capabilities beyond text\n",
    "4. **State Management** is crucial for coherent behavior\n",
    "5. **Error Handling** makes agents robust\n",
    "\n",
    "### 🚀 What's Next?\n",
    "\n",
    "**Module 2: Memory & Learning**\n",
    "- Persistent memory systems\n",
    "- Learning from experience\n",
    "- Performance optimization\n",
    "- Advanced context management\n",
    "\n",
    "**Module 3: Tool Mastery**\n",
    "- Database integration\n",
    "- API connections\n",
    "- File processing\n",
    "- Tool composition\n",
    "\n",
    "**Module 4: Planning & Goals**\n",
    "- Hierarchical planning\n",
    "- Goal decomposition\n",
    "- Multi-agent coordination\n",
    "- Complex workflows\n",
    "\n",
    "### 💪 Challenge Yourself\n",
    "\n",
    "Before moving to Module 2, try:\n",
    "1. Build an agent that can play 20 questions\n",
    "2. Create a tool that interacts with files\n",
    "3. Implement conversation memory\n",
    "4. Add vision capabilities (image analysis)\n",
    "\n",
    "### 📚 Additional Resources\n",
    "\n",
    "- **ReAct Paper**: \"ReAct: Synergizing Reasoning and Acting\"\n",
    "- **Ollama Docs**: https://ollama.ai/\n",
    "- **Agent Architectures**: Research cognitive architectures\n",
    "- **Prompt Engineering**: OpenAI's prompt engineering guide\n",
    "\n",
    "---\n",
    "\n",
    "🎉 **Congratulations!** You've built your first AI agent from scratch using first principles. You now understand the foundations that all agent systems build upon.\n",
    "\n",
    "Ready for Module 2? Let's add memory and learning! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}