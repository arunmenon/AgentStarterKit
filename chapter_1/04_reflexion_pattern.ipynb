{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.4: Reflexion - Verbal Reinforcement Learning 🎯\n",
    "\n",
    "**Duration**: 15 minutes  \n",
    "**Level**: Advanced  \n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this module, you'll understand:\n",
    "- How Reflexion achieves 91% accuracy on HumanEval\n",
    "- Verbal reinforcement learning concepts\n",
    "- Self-reflection for agent improvement\n",
    "- Implementation of reflection loops\n",
    "\n",
    "## 💡 Key Innovation\n",
    "\n",
    "**Use language as the reward signal!**\n",
    "\n",
    "Traditional RL: Numeric rewards → Weight updates  \n",
    "Reflexion: Verbal feedback → Memory updates  \n",
    "\n",
    "Results:\n",
    "- **91% accuracy** on HumanEval (vs 80% GPT-4)\n",
    "- **10% improvement** on AlfWorld tasks\n",
    "- No fine-tuning required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "class TaskStatus(Enum):\n",
    "    \"\"\"Possible outcomes of task execution\"\"\"\n",
    "    SUCCESS = \"success\"\n",
    "    FAILURE = \"failure\"\n",
    "    PARTIAL = \"partial\"\n",
    "\n",
    "@dataclass\n",
    "class TaskAttempt:\n",
    "    \"\"\"Record of a single attempt at solving a task\"\"\"\n",
    "    attempt_number: int\n",
    "    approach: str\n",
    "    implementation: str\n",
    "    result: str\n",
    "    status: TaskStatus\n",
    "    execution_trace: List[str] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class Reflection:\n",
    "    \"\"\"Self-reflection on a task attempt\"\"\"\n",
    "    attempt: TaskAttempt\n",
    "    what_went_wrong: str\n",
    "    why_it_failed: str\n",
    "    lessons_learned: List[str]\n",
    "    improved_approach: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 The Reflexion Architecture\n",
    "\n",
    "Reflexion has three key components:\n",
    "\n",
    "```\n",
    "┌─────────────┐     ┌──────────────┐     ┌─────────────┐\n",
    "│   ACTOR     │────▶│  EVALUATOR   │────▶│   SELF-     │\n",
    "│             │     │              │     │ REFLECTION  │\n",
    "│ Generates   │     │ Tests if     │     │ Analyzes    │\n",
    "│ solutions   │     │ correct      │     │ failures    │\n",
    "└─────────────┘     └──────────────┘     └─────────────┘\n",
    "       ▲                                         │\n",
    "       └─────────────────────────────────────────┘\n",
    "                  Verbal feedback loop\n",
    "```\n",
    "\n",
    "The key insight: **Reflection becomes memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflexionMemory:\n",
    "    \"\"\"Episodic memory that stores reflections\"\"\"\n",
    "    \n",
    "    def __init__(self, max_reflections: int = 10):\n",
    "        self.reflections: List[Reflection] = []\n",
    "        self.max_reflections = max_reflections\n",
    "        \n",
    "    def add_reflection(self, reflection: Reflection):\n",
    "        \"\"\"Add a reflection to memory\"\"\"\n",
    "        self.reflections.append(reflection)\n",
    "        \n",
    "        # Keep only most recent reflections\n",
    "        if len(self.reflections) > self.max_reflections:\n",
    "            self.reflections = self.reflections[-self.max_reflections:]\n",
    "    \n",
    "    def get_relevant_lessons(self, task: str) -> List[str]:\n",
    "        \"\"\"Extract lessons relevant to current task\"\"\"\n",
    "        all_lessons = []\n",
    "        for reflection in self.reflections:\n",
    "            all_lessons.extend(reflection.lessons_learned)\n",
    "        \n",
    "        # In practice, use semantic similarity to filter\n",
    "        # For now, return all recent lessons\n",
    "        return all_lessons[-5:]  # Last 5 lessons\n",
    "    \n",
    "    def get_memory_prompt(self) -> str:\n",
    "        \"\"\"Format memory for inclusion in prompts\"\"\"\n",
    "        if not self.reflections:\n",
    "            return \"No previous reflections available.\"\n",
    "        \n",
    "        prompt = \"Previous reflections and lessons learned:\\n\\n\"\n",
    "        \n",
    "        for reflection in self.reflections[-3:]:  # Last 3 reflections\n",
    "            prompt += f\"Attempt {reflection.attempt.attempt_number}:\\n\"\n",
    "            prompt += f\"- What went wrong: {reflection.what_went_wrong}\\n\"\n",
    "            prompt += f\"- Why: {reflection.why_it_failed}\\n\"\n",
    "            prompt += f\"- Lessons: {', '.join(reflection.lessons_learned)}\\n\"\n",
    "            prompt += f\"- Better approach: {reflection.improved_approach}\\n\\n\"\n",
    "            \n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎭 Component 1: The Actor\n",
    "\n",
    "The Actor generates solutions based on:\n",
    "1. The task description\n",
    "2. Previous reflections\n",
    "3. Learned lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflexionActor:\n",
    "    \"\"\"Generates solutions using reflection memory\"\"\"\n",
    "    \n",
    "    def __init__(self, memory: ReflexionMemory):\n",
    "        self.memory = memory\n",
    "        \n",
    "    def generate_solution(self, task: str, attempt_number: int) -> TaskAttempt:\n",
    "        \"\"\"Generate a solution incorporating past reflections\"\"\"\n",
    "        \n",
    "        # Build prompt with memory\n",
    "        prompt = f\"\"\"Task: {task}\n",
    "\n",
    "{self.memory.get_memory_prompt()}\n",
    "\n",
    "Based on any previous reflections and lessons learned, \n",
    "generate a solution for this task.\n",
    "\n",
    "Approach:\n",
    "Implementation:\n",
    "\"\"\"\n",
    "        \n",
    "        # Simulate LLM response incorporating lessons\n",
    "        if attempt_number == 1:\n",
    "            # First attempt - naive approach\n",
    "            approach = \"Direct implementation without edge case handling\"\n",
    "            implementation = \"def solve(x): return x * 2  # Simple but incomplete\"\n",
    "        else:\n",
    "            # Later attempts - incorporate lessons\n",
    "            relevant_lessons = self.memory.get_relevant_lessons(task)\n",
    "            if relevant_lessons:\n",
    "                approach = f\"Improved approach addressing: {', '.join(relevant_lessons[:2])}\"\n",
    "                implementation = \"def solve(x):\\n    if x < 0: return 0\\n    return x * 2  # Now handles edge cases\"\n",
    "            else:\n",
    "                approach = \"Refined approach with better error handling\"\n",
    "                implementation = \"def solve(x): return max(0, x * 2)\"\n",
    "        \n",
    "        return TaskAttempt(\n",
    "            attempt_number=attempt_number,\n",
    "            approach=approach,\n",
    "            implementation=implementation,\n",
    "            result=\"\",  # To be filled by evaluator\n",
    "            status=TaskStatus.FAILURE  # To be updated\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Component 2: The Evaluator\n",
    "\n",
    "The Evaluator:\n",
    "- Tests the solution\n",
    "- Determines success/failure\n",
    "- Provides execution traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflexionEvaluator:\n",
    "    \"\"\"Evaluates solutions and provides feedback\"\"\"\n",
    "    \n",
    "    def evaluate(self, attempt: TaskAttempt, test_cases: List[Dict]) -> TaskAttempt:\n",
    "        \"\"\"Run solution against test cases\"\"\"\n",
    "        \n",
    "        passed = 0\n",
    "        total = len(test_cases)\n",
    "        execution_trace = []\n",
    "        \n",
    "        # Simulate test execution\n",
    "        for i, test in enumerate(test_cases):\n",
    "            if attempt.attempt_number == 1:\n",
    "                # First attempt fails on negative numbers\n",
    "                if test.get(\"input\", 0) < 0:\n",
    "                    execution_trace.append(f\"Test {i+1}: FAILED - Negative input not handled\")\n",
    "                else:\n",
    "                    execution_trace.append(f\"Test {i+1}: PASSED\")\n",
    "                    passed += 1\n",
    "            else:\n",
    "                # Improved attempts pass all tests\n",
    "                execution_trace.append(f\"Test {i+1}: PASSED\")\n",
    "                passed += 1\n",
    "        \n",
    "        # Update attempt with results\n",
    "        attempt.execution_trace = execution_trace\n",
    "        attempt.result = f\"Passed {passed}/{total} tests\"\n",
    "        \n",
    "        if passed == total:\n",
    "            attempt.status = TaskStatus.SUCCESS\n",
    "        elif passed > 0:\n",
    "            attempt.status = TaskStatus.PARTIAL\n",
    "        else:\n",
    "            attempt.status = TaskStatus.FAILURE\n",
    "            \n",
    "        return attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💭 Component 3: Self-Reflection\n",
    "\n",
    "This is where the magic happens! The agent:\n",
    "1. Analyzes what went wrong\n",
    "2. Understands why it failed\n",
    "3. Extracts generalizable lessons\n",
    "4. Proposes improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflexionSelfReflector:\n",
    "    \"\"\"Generates reflections from failed attempts\"\"\"\n",
    "    \n",
    "    def reflect(self, attempt: TaskAttempt, task: str) -> Reflection:\n",
    "        \"\"\"Analyze failure and extract lessons\"\"\"\n",
    "        \n",
    "        reflection_prompt = f\"\"\"Task: {task}\n",
    "Attempt {attempt.attempt_number}:\n",
    "- Approach: {attempt.approach}\n",
    "- Implementation: {attempt.implementation}\n",
    "- Result: {attempt.result}\n",
    "- Status: {attempt.status.value}\n",
    "\n",
    "Execution trace:\n",
    "{chr(10).join(attempt.execution_trace)}\n",
    "\n",
    "Analyze this attempt:\n",
    "1. What specifically went wrong?\n",
    "2. Why did this approach fail?\n",
    "3. What lessons can be learned?\n",
    "4. What would be a better approach?\n",
    "\"\"\"\n",
    "        \n",
    "        # Simulate reflection (in practice, use LLM)\n",
    "        if attempt.status == TaskStatus.FAILURE or attempt.status == TaskStatus.PARTIAL:\n",
    "            # Analyze the execution trace\n",
    "            failed_on_negative = any(\"Negative\" in trace for trace in attempt.execution_trace)\n",
    "            \n",
    "            if failed_on_negative:\n",
    "                what_went_wrong = \"Solution failed on negative input values\"\n",
    "                why_it_failed = \"No validation or edge case handling for negative numbers\"\n",
    "                lessons = [\n",
    "                    \"Always validate input ranges\",\n",
    "                    \"Consider edge cases like negative numbers\",\n",
    "                    \"Add defensive programming checks\"\n",
    "                ]\n",
    "                improved_approach = \"Add input validation and handle edge cases explicitly\"\n",
    "            else:\n",
    "                what_went_wrong = \"Solution had logical errors\"\n",
    "                why_it_failed = \"Incorrect algorithm implementation\"\n",
    "                lessons = [\n",
    "                    \"Test algorithm logic thoroughly\",\n",
    "                    \"Break down complex operations\"\n",
    "                ]\n",
    "                improved_approach = \"Reimplement with clearer logic flow\"\n",
    "        else:\n",
    "            # Success - still reflect on what worked\n",
    "            what_went_wrong = \"Nothing - solution succeeded\"\n",
    "            why_it_failed = \"N/A - successful approach\"\n",
    "            lessons = [\"This approach pattern works well\"]\n",
    "            improved_approach = \"Continue with similar patterns\"\n",
    "            \n",
    "        return Reflection(\n",
    "            attempt=attempt,\n",
    "            what_went_wrong=what_went_wrong,\n",
    "            why_it_failed=why_it_failed,\n",
    "            lessons_learned=lessons,\n",
    "            improved_approach=improved_approach\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 The Complete Reflexion Loop\n",
    "\n",
    "Now let's put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Starting Reflexion Agent\n",
      "Task: Implement a function that doubles positive numbers and returns 0 for negative numbers\n",
      "\n",
      "========================================\n",
      "Attempt 1\n",
      "========================================\n",
      "Approach: Direct implementation without edge case handling\n",
      "Implementation: def solve(x): return x * 2  # Simple but incomplete\n",
      "Result: Passed 2/4 tests\n",
      "Status: partial\n",
      "\n",
      "📝 Reflection:\n",
      "What went wrong: Solution failed on negative input values\n",
      "Why: No validation or edge case handling for negative numbers\n",
      "Lessons learned:\n",
      "- Always validate input ranges\n",
      "- Consider edge cases like negative numbers\n",
      "- Add defensive programming checks\n",
      "\n",
      "========================================\n",
      "Attempt 2\n",
      "========================================\n",
      "Approach: Improved approach addressing: Always validate input ranges, Consider edge cases like negative numbers\n",
      "Implementation: def solve(x):\n",
      "    if x < 0: return 0\n",
      "    return x * 2  # Now handles edge cases\n",
      "Result: Passed 4/4 tests\n",
      "Status: success\n",
      "\n",
      "✅ Task completed successfully!\n",
      "\n",
      "📊 Performance Summary:\n",
      "Total attempts: 2\n",
      "Success rate improvement: 50.0% → 100.0%\n",
      "\n",
      "💡 Lessons learned:\n",
      "- Always validate input ranges\n",
      "- Consider edge cases like negative numbers\n",
      "- Add defensive programming checks\n"
     ]
    }
   ],
   "source": [
    "class ReflexionAgent:\n",
    "    \"\"\"Complete Reflexion agent with all components\"\"\"\n",
    "    \n",
    "    def __init__(self, max_attempts: int = 5):\n",
    "        self.max_attempts = max_attempts\n",
    "        self.memory = ReflexionMemory()\n",
    "        self.actor = ReflexionActor(self.memory)\n",
    "        self.evaluator = ReflexionEvaluator()\n",
    "        self.reflector = ReflexionSelfReflector()\n",
    "        \n",
    "    def solve(self, task: str, test_cases: List[Dict]) -> Tuple[bool, List[TaskAttempt]]:\n",
    "        \"\"\"Solve task using Reflexion loop\"\"\"\n",
    "        print(f\"🎯 Starting Reflexion Agent\")\n",
    "        print(f\"Task: {task}\\n\")\n",
    "        \n",
    "        attempts = []\n",
    "        \n",
    "        for attempt_num in range(1, self.max_attempts + 1):\n",
    "            print(\"=\" * 40)\n",
    "            print(f\"Attempt {attempt_num}\")\n",
    "            print(\"=\" * 40)\n",
    "            \n",
    "            # 1. Actor generates solution\n",
    "            attempt = self.actor.generate_solution(task, attempt_num)\n",
    "            \n",
    "            # 2. Evaluator tests solution\n",
    "            attempt = self.evaluator.evaluate(attempt, test_cases)\n",
    "            attempts.append(attempt)\n",
    "            \n",
    "            print(f\"Approach: {attempt.approach}\")\n",
    "            print(f\"Implementation: {attempt.implementation}\")\n",
    "            print(f\"Result: {attempt.result}\")\n",
    "            print(f\"Status: {attempt.status.value}\")\n",
    "            \n",
    "            # 3. Check if successful\n",
    "            if attempt.status == TaskStatus.SUCCESS:\n",
    "                print(\"\\n✅ Task completed successfully!\")\n",
    "                return True, attempts\n",
    "            \n",
    "            # 4. Self-reflect on failure\n",
    "            reflection = self.reflector.reflect(attempt, task)\n",
    "            self.memory.add_reflection(reflection)\n",
    "            \n",
    "            print(f\"\\n📝 Reflection:\")\n",
    "            print(f\"What went wrong: {reflection.what_went_wrong}\")\n",
    "            print(f\"Why: {reflection.why_it_failed}\")\n",
    "            print(f\"Lessons learned:\")\n",
    "            for lesson in reflection.lessons_learned:\n",
    "                print(f\"- {lesson}\")\n",
    "            print()\n",
    "        \n",
    "        print(\"\\n❌ Max attempts reached without success\")\n",
    "        return False, attempts\n",
    "\n",
    "# Test the Reflexion agent\n",
    "agent = ReflexionAgent(max_attempts=3)\n",
    "\n",
    "# Define task and test cases\n",
    "task = \"Implement a function that doubles positive numbers and returns 0 for negative numbers\"\n",
    "test_cases = [\n",
    "    {\"input\": 5, \"expected\": 10},\n",
    "    {\"input\": -3, \"expected\": 0},\n",
    "    {\"input\": 0, \"expected\": 0},\n",
    "    {\"input\": -7, \"expected\": 0}\n",
    "]\n",
    "\n",
    "# Run Reflexion loop\n",
    "success, attempts = agent.solve(task, test_cases)\n",
    "\n",
    "# Show improvement\n",
    "print(\"\\n📊 Performance Summary:\")\n",
    "print(f\"Total attempts: {len(attempts)}\")\n",
    "if len(attempts) > 1:\n",
    "    first_score = int(attempts[0].result.split('/')[0].split()[-1])\n",
    "    last_score = int(attempts[-1].result.split('/')[0].split()[-1])\n",
    "    total_tests = int(attempts[0].result.split('/')[1].split()[0])\n",
    "    print(f\"Success rate improvement: {first_score/total_tests*100:.1f}% → {last_score/total_tests*100:.1f}%\")\n",
    "\n",
    "# Show accumulated lessons\n",
    "print(\"\\n💡 Lessons learned:\")\n",
    "for lesson in agent.memory.get_relevant_lessons(task):\n",
    "    print(f\"- {lesson}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Why Reflexion Works So Well\n",
    "\n",
    "### 1. **Natural Language Feedback**\n",
    "- No numeric rewards to tune\n",
    "- Rich, interpretable feedback\n",
    "- Aligns with how humans learn\n",
    "\n",
    "### 2. **Episodic Memory**\n",
    "- Stores specific experiences\n",
    "- Retrieves relevant lessons\n",
    "- Builds on past failures\n",
    "\n",
    "### 3. **Explicit Reasoning**\n",
    "- Forces analysis of failures\n",
    "- Extracts general principles\n",
    "- Plans improvements\n",
    "\n",
    "### 4. **No Fine-tuning**\n",
    "- Works with any LLM\n",
    "- No gradient updates needed\n",
    "- Immediate improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔬 Advanced Reflexion Techniques\n",
    "\n",
    "### 1. Hierarchical Reflection\n",
    "\n",
    "Reflect at multiple levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical Reflection Analysis:\n",
      "================================\n",
      "\n",
      "🔧 Implementation Level:\n",
      "- Syntax errors in line 3\n",
      "- Missing return statement\n",
      "- Incorrect variable naming\n",
      "\n",
      "🎯 Strategy Level:\n",
      "- Wrong algorithm choice\n",
      "- Inefficient approach\n",
      "- Missing edge case consideration\n",
      "\n",
      "📐 Task Understanding:\n",
      "- Misunderstood requirements\n",
      "- Incorrect assumptions\n",
      "- Missing constraints\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class HierarchicalReflection:\n",
    "    \"\"\"Multi-level reflection for deeper learning\"\"\"\n",
    "    implementation_issues: List[str]  # Code-level problems\n",
    "    strategy_issues: List[str]        # Approach-level problems  \n",
    "    understanding_issues: List[str]   # Task comprehension problems\n",
    "    \n",
    "    def get_priority_lessons(self) -> List[str]:\n",
    "        \"\"\"Extract most important lessons\"\"\"\n",
    "        lessons = []\n",
    "        \n",
    "        # Understanding issues are most critical\n",
    "        if self.understanding_issues:\n",
    "            lessons.append(f\"Clarify task requirements: {self.understanding_issues[0]}\")\n",
    "            \n",
    "        # Then strategy\n",
    "        if self.strategy_issues:\n",
    "            lessons.append(f\"Improve approach: {self.strategy_issues[0]}\")\n",
    "            \n",
    "        # Finally implementation\n",
    "        if self.implementation_issues:\n",
    "            lessons.append(f\"Fix code issues: {self.implementation_issues[0]}\")\n",
    "            \n",
    "        return lessons\n",
    "\n",
    "# Example hierarchical reflection\n",
    "hierarchical = HierarchicalReflection(\n",
    "    implementation_issues=[\"Syntax errors in line 3\", \"Missing return statement\", \"Incorrect variable naming\"],\n",
    "    strategy_issues=[\"Wrong algorithm choice\", \"Inefficient approach\", \"Missing edge case consideration\"],\n",
    "    understanding_issues=[\"Misunderstood requirements\", \"Incorrect assumptions\", \"Missing constraints\"]\n",
    ")\n",
    "\n",
    "print(\"Hierarchical Reflection Analysis:\")\n",
    "print(\"=\" * 32)\n",
    "print(\"\\n🔧 Implementation Level:\")\n",
    "for issue in hierarchical.implementation_issues:\n",
    "    print(f\"- {issue}\")\n",
    "print(\"\\n🎯 Strategy Level:\")\n",
    "for issue in hierarchical.strategy_issues:\n",
    "    print(f\"- {issue}\")\n",
    "print(\"\\n📐 Task Understanding:\")\n",
    "for issue in hierarchical.understanding_issues:\n",
    "    print(f\"- {issue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cross-Task Transfer\n",
    "\n",
    "Apply lessons across different tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Task Lesson Application:\n",
      "==============================\n",
      "\n",
      "Original lesson: Always validate input types\n",
      "Generalized: Always validate input parameters\n",
      "\n",
      "Applications:\n",
      "- String processing: Check for null/empty strings\n",
      "- Array operations: Verify array bounds and size\n",
      "- API calls: Validate request parameters\n",
      "- File operations: Check file existence and permissions\n"
     ]
    }
   ],
   "source": [
    "class CrossTaskMemory:\n",
    "    \"\"\"Memory that generalizes lessons across tasks\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.task_patterns = {\n",
    "            \"validation\": [\n",
    "                \"Always validate input types\",\n",
    "                \"Check boundary conditions\",\n",
    "                \"Handle null/empty cases\"\n",
    "            ],\n",
    "            \"error_handling\": [\n",
    "                \"Use try-except blocks\",\n",
    "                \"Provide meaningful error messages\",\n",
    "                \"Fail gracefully\"\n",
    "            ],\n",
    "            \"optimization\": [\n",
    "                \"Consider time complexity\",\n",
    "                \"Minimize memory usage\",\n",
    "                \"Cache repeated computations\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def extract_pattern(self, lesson: str) -> Optional[str]:\n",
    "        \"\"\"Identify general pattern from specific lesson\"\"\"\n",
    "        for pattern_type, patterns in self.task_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if any(word in lesson.lower() for word in pattern.lower().split()):\n",
    "                    return pattern_type\n",
    "        return None\n",
    "    \n",
    "    def apply_to_new_task(self, lesson: str, new_task_type: str) -> str:\n",
    "        \"\"\"Adapt lesson to new task context\"\"\"\n",
    "        pattern = self.extract_pattern(lesson)\n",
    "        \n",
    "        if pattern == \"validation\":\n",
    "            adaptations = {\n",
    "                \"string\": \"Check for null/empty strings\",\n",
    "                \"array\": \"Verify array bounds and size\",\n",
    "                \"api\": \"Validate request parameters\",\n",
    "                \"file\": \"Check file existence and permissions\"\n",
    "            }\n",
    "        elif pattern == \"error_handling\":\n",
    "            adaptations = {\n",
    "                \"string\": \"Handle encoding errors\",\n",
    "                \"array\": \"Catch index out of bounds\",\n",
    "                \"api\": \"Handle network timeouts\",\n",
    "                \"file\": \"Handle IO exceptions\"\n",
    "            }\n",
    "        else:\n",
    "            return lesson  # Return original if no pattern match\n",
    "            \n",
    "        return adaptations.get(new_task_type, lesson)\n",
    "\n",
    "# Example cross-task transfer\n",
    "cross_memory = CrossTaskMemory()\n",
    "original_lesson = \"Always validate input types\"\n",
    "pattern = cross_memory.extract_pattern(original_lesson)\n",
    "\n",
    "print(\"Cross-Task Lesson Application:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"\\nOriginal lesson: {original_lesson}\")\n",
    "print(f\"Generalized: Always validate input parameters\")\n",
    "print(\"\\nApplications:\")\n",
    "\n",
    "for task_type in [\"string\", \"array\", \"api\", \"file\"]:\n",
    "    adapted = cross_memory.apply_to_new_task(original_lesson, task_type)\n",
    "    print(f\"- {task_type.capitalize()} processing: {adapted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confidence-Based Reflection\n",
    "\n",
    "Reflect more on low-confidence attempts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence-Based Reflection Depth:\n",
      "==================================\n",
      "\n",
      "High confidence (0.9): Standard - 1 reflection questions\n",
      "Medium confidence (0.6): Deep - 3 reflection questions\n",
      "Low confidence (0.3): Intensive - 5 reflection questions\n",
      "\n",
      "Intensive reflection questions:\n",
      "1. What assumptions did I make that might be wrong?\n",
      "2. What edge cases did I not consider?\n",
      "3. Is there a completely different approach?\n",
      "4. What would an expert do differently?\n",
      "5. What fundamental concept am I missing?\n"
     ]
    }
   ],
   "source": [
    "def get_reflection_depth(confidence: float) -> str:\n",
    "    \"\"\"Determine how deep to reflect based on confidence\"\"\"\n",
    "    if confidence > 0.8:\n",
    "        return \"standard\"\n",
    "    elif confidence > 0.5:\n",
    "        return \"deep\"\n",
    "    else:\n",
    "        return \"intensive\"\n",
    "\n",
    "def generate_reflection_questions(depth: str) -> List[str]:\n",
    "    \"\"\"Generate reflection prompts based on depth\"\"\"\n",
    "    questions = {\n",
    "        \"standard\": [\n",
    "            \"What was the main issue?\"\n",
    "        ],\n",
    "        \"deep\": [\n",
    "            \"What was the main issue?\",\n",
    "            \"Why did I choose this approach?\",\n",
    "            \"What alternative approaches exist?\"\n",
    "        ],\n",
    "        \"intensive\": [\n",
    "            \"What assumptions did I make that might be wrong?\",\n",
    "            \"What edge cases did I not consider?\",\n",
    "            \"Is there a completely different approach?\",\n",
    "            \"What would an expert do differently?\",\n",
    "            \"What fundamental concept am I missing?\"\n",
    "        ]\n",
    "    }\n",
    "    return questions.get(depth, questions[\"standard\"])\n",
    "\n",
    "# Example confidence-based reflection\n",
    "confidences = [0.9, 0.6, 0.3]\n",
    "print(\"Confidence-Based Reflection Depth:\")\n",
    "print(\"=\" * 34)\n",
    "\n",
    "for conf in confidences:\n",
    "    depth = get_reflection_depth(conf)\n",
    "    questions = generate_reflection_questions(depth)\n",
    "    print(f\"\\n{depth.capitalize()} confidence ({conf}): {depth.capitalize()} - {len(questions)} reflection questions\")\n",
    "\n",
    "# Show intensive questions\n",
    "print(\"\\nIntensive reflection questions:\")\n",
    "for i, q in enumerate(generate_reflection_questions(\"intensive\"), 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Reflexion Performance Analysis\n",
    "\n",
    "From the research, Reflexion shows impressive results:\n",
    "\n",
    "### HumanEval (Code Generation)\n",
    "- GPT-4 baseline: 80%\n",
    "- GPT-4 + Reflexion: **91%** ✨\n",
    "- Improvement: **13.75%**\n",
    "\n",
    "### AlfWorld (Sequential Decision Making)\n",
    "- ReAct baseline: 75%\n",
    "- ReAct + Reflexion: **88%**\n",
    "- Improvement: **17.3%**\n",
    "\n",
    "### Key Insights:\n",
    "1. **Few-shot learning**: 1-2 reflections often sufficient\n",
    "2. **Generalizable**: Lessons transfer across similar tasks\n",
    "3. **Interpretable**: Can inspect reasoning process\n",
    "4. **Efficient**: No model updates required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Key Takeaways\n",
    "\n",
    "1. **Verbal feedback > Numeric rewards** for LLM learning\n",
    "2. **Self-reflection** creates reusable knowledge\n",
    "3. **Episodic memory** enables experience replay\n",
    "4. **No fine-tuning** needed - works with any LLM\n",
    "5. **91% accuracy** demonstrates effectiveness\n",
    "\n",
    "## 🚀 Next Steps\n",
    "\n",
    "In Module 1.5, we'll explore:\n",
    "- **Advanced Prompting**: 58 techniques from 2024-2025\n",
    "- Agent-specific prompting strategies\n",
    "- Prompt optimization methods\n",
    "\n",
    "Ready to master the art of prompting? Let's go! 🎨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
